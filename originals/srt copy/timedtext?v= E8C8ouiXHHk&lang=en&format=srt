1
00:00:00,000 --> 00:00:03,820

2
00:00:03,820 --> 00:00:05,940
JUSTIN UBERTI: So what you all
think of the Google Glass

3
00:00:05,940 --> 00:00:07,247
Hangout this morning?

4
00:00:07,247 --> 00:00:10,110
[AUDIENCE CHEERING]

5
00:00:10,110 --> 00:00:13,260
JUSTIN UBERTI: What an amazing
way to show off the power of

6
00:00:13,260 --> 00:00:14,705
real-time communication.

7
00:00:14,705 --> 00:00:16,570
When I first heard about it,
they're going to jump out of

8
00:00:16,570 --> 00:00:19,260
an airship and have it all in a
Hangout, I was like, that's

9
00:00:19,260 --> 00:00:19,990
pretty incredible.

10
00:00:19,990 --> 00:00:21,800
But anyway, I'm Justin Uberti.

11
00:00:21,800 --> 00:00:25,420
And today, I'd like to tell
you all about WebRTC, a

12
00:00:25,420 --> 00:00:27,530
project to bring real-time
communication--

13
00:00:27,530 --> 00:00:29,100
RTC--

14
00:00:29,100 --> 00:00:30,350
to the open web platform.

15
00:00:30,350 --> 00:00:33,080

16
00:00:33,080 --> 00:00:37,240
So I currently work on the
WebRTC team here at Google,

17
00:00:37,240 --> 00:00:39,410
which is part of the
Chrome project.

18
00:00:39,410 --> 00:00:43,020
Before joining WebRTC, I was
the lead in the Google Talk

19
00:00:43,020 --> 00:00:45,480
team, where we built some really
exciting applications,

20
00:00:45,480 --> 00:00:48,500
and also learned a lot of really
hard lessons about what

21
00:00:48,500 --> 00:00:52,490
it takes to do these kinds
of apps in a browser.

22
00:00:52,490 --> 00:00:54,450
I also kind of learned that some
people on the internet

23
00:00:54,450 --> 00:00:56,710
think I have really
small hands.

24
00:00:56,710 --> 00:00:57,960
I don't get it.

25
00:00:57,960 --> 00:01:00,720

26
00:01:00,720 --> 00:01:02,670
So enough about me.

27
00:01:02,670 --> 00:01:04,180
Let me see what kind of
developers we have in the

28
00:01:04,180 --> 00:01:05,580
audience today.

29
00:01:05,580 --> 00:01:07,160
Raise your hand if you're
really familiar with the

30
00:01:07,160 --> 00:01:08,410
following technologies.

31
00:01:08,410 --> 00:01:10,490

32
00:01:10,490 --> 00:01:12,884
WebRTC?

33
00:01:12,884 --> 00:01:14,800
OK.

34
00:01:14,800 --> 00:01:17,090
HTML5?

35
00:01:17,090 --> 00:01:18,310
Good.

36
00:01:18,310 --> 00:01:19,560
WebSockets?

37
00:01:19,560 --> 00:01:21,530

38
00:01:21,530 --> 00:01:24,450
App Engine?

39
00:01:24,450 --> 00:01:25,608
SIP?

40
00:01:25,608 --> 00:01:27,700
OK.

41
00:01:27,700 --> 00:01:29,580
H 323?

42
00:01:29,580 --> 00:01:30,140
OK.

43
00:01:30,140 --> 00:01:32,070
You folks who raised your
hands, you have my

44
00:01:32,070 --> 00:01:33,320
condolences.

45
00:01:33,320 --> 00:01:40,170

46
00:01:40,170 --> 00:01:43,310
So what exactly is WebRTC?

47
00:01:43,310 --> 00:01:46,930
Well, let me tell you
a little story.

48
00:01:46,930 --> 00:01:48,790
A couple years ago, when we
are working on what would

49
00:01:48,790 --> 00:01:51,990
become Hangouts, the Chrome
team approached us.

50
00:01:51,990 --> 00:01:55,000
And they said, the open web
platform has some amazing

51
00:01:55,000 --> 00:01:56,460
technology.

52
00:01:56,460 --> 00:01:58,490
And people are building
incredible apps with it.

53
00:01:58,490 --> 00:02:01,030
But there's one big
gap remaining.

54
00:02:01,030 --> 00:02:04,220
To build apps like Google Video
Chat, you need plugins.

55
00:02:04,220 --> 00:02:07,160
And these plugins have all sorts
of problems, security,

56
00:02:07,160 --> 00:02:08,590
everything.

57
00:02:08,590 --> 00:02:11,500
What would it take to take the
stuff you built for Google

58
00:02:11,500 --> 00:02:13,620
Video Chat and Hangouts,
and make it part of

59
00:02:13,620 --> 00:02:16,410
the open web platform?

60
00:02:16,410 --> 00:02:19,440
Well, we said, it would
be really complicated.

61
00:02:19,440 --> 00:02:21,110
I mean, we'd have all
these technology

62
00:02:21,110 --> 00:02:22,250
issues to figure out.

63
00:02:22,250 --> 00:02:23,710
And we'd have to deal
with like codec

64
00:02:23,710 --> 00:02:25,870
licensing, and open sourcing.

65
00:02:25,870 --> 00:02:28,700
And most of all, we'd have to
work with other browser

66
00:02:28,700 --> 00:02:31,470
manufacturers and other industry
players to make an

67
00:02:31,470 --> 00:02:34,740
actual standard for something
that can be implemented across

68
00:02:34,740 --> 00:02:37,760
all browsers and across
the entire web.

69
00:02:37,760 --> 00:02:40,710
And so in typical Google
fashion, the response we got

70
00:02:40,710 --> 00:02:44,000
back was, sounds like a plan.

71
00:02:44,000 --> 00:02:46,090
When can we have it?

72
00:02:46,090 --> 00:02:48,110
So we got to work.

73
00:02:48,110 --> 00:02:51,290
Where we didn't have the right
technology pieces in house, we

74
00:02:51,290 --> 00:02:54,690
went out and we acquired state
of the art, the very best

75
00:02:54,690 --> 00:02:56,490
technology out there.

76
00:02:56,490 --> 00:02:59,030
We assembled these pieces
into a system.

77
00:02:59,030 --> 00:03:01,500
And as we started talking to
other people, and we talked to

78
00:03:01,500 --> 00:03:07,220
other browser manufacturers,
Firefox, Opera, Microsoft.

79
00:03:07,220 --> 00:03:10,150
We talked to people who would
build apps on this platform,

80
00:03:10,150 --> 00:03:12,360
people like Skype, people
like Cisco.

81
00:03:12,360 --> 00:03:16,220
And we talked to the typical
telecom providers, folks like

82
00:03:16,220 --> 00:03:18,800
Ericsson, AT&T.

83
00:03:18,800 --> 00:03:22,590
They were all super excited
about this because it's

84
00:03:22,590 --> 00:03:26,040
potential, not just for the
web, but for the entire

85
00:03:26,040 --> 00:03:28,400
communications industry.

86
00:03:28,400 --> 00:03:31,700
So that's the premise of WebRTC,
RTC to build real-time

87
00:03:31,700 --> 00:03:34,720
communications into the fabric
of the web, where every

88
00:03:34,720 --> 00:03:37,300
browser has a built in, state
of the art communication

89
00:03:37,300 --> 00:03:42,460
stack, and create a new open
platform that any application

90
00:03:42,460 --> 00:03:44,160
and any device can use
to communicate.

91
00:03:44,160 --> 00:03:47,130

92
00:03:47,130 --> 00:03:48,760
So think about that.

93
00:03:48,760 --> 00:03:51,830
This is where we're having,
the ability to get the

94
00:03:51,830 --> 00:03:53,320
communications industry--

95
00:03:53,320 --> 00:03:55,840
a $2 trillion industry--

96
00:03:55,840 --> 00:03:58,080
moving at web speed.

97
00:03:58,080 --> 00:04:00,280
And not only will the developers
be able to build

98
00:04:00,280 --> 00:04:03,310
and deploy voice and video apps,
just like any other web

99
00:04:03,310 --> 00:04:06,340
app, but we'll also start to see
communication being built

100
00:04:06,340 --> 00:04:08,970
in as a feature to all
sorts of apps.

101
00:04:08,970 --> 00:04:12,575
In a game, the ability to see
the opponent's face right as

102
00:04:12,575 --> 00:04:14,320
you checkmate them.

103
00:04:14,320 --> 00:04:17,630
Or in customer service on a
website, a shopping website,

104
00:04:17,630 --> 00:04:20,980
to be able to talk to a customer
service rep live in

105
00:04:20,980 --> 00:04:24,620
person with a single click.

106
00:04:24,620 --> 00:04:28,220
As WebRTC takes hold across
computers and all sorts of

107
00:04:28,220 --> 00:04:32,170
devices, we have the real
ability to create the next

108
00:04:32,170 --> 00:04:35,270
generation phone network, where
every WebRTC enabled

109
00:04:35,270 --> 00:04:37,630
device can communicate
with amazing

110
00:04:37,630 --> 00:04:38,880
audio and video quality.

111
00:04:38,880 --> 00:04:41,800

112
00:04:41,800 --> 00:04:43,930
So take this quote
from NoJitter.

113
00:04:43,930 --> 00:04:47,045
This is a communications
industry blog.

114
00:04:47,045 --> 00:04:52,370
"WebRTC and HTML5 could enable
the same transformation for

115
00:04:52,370 --> 00:04:57,310
real time that the original
browser did for information."

116
00:04:57,310 --> 00:04:59,930
That's a pretty lofty
comparison.

117
00:04:59,930 --> 00:05:02,110
So how do we get there?

118
00:05:02,110 --> 00:05:05,170
Well first, we need to get
WebRTC in the hands of you,

119
00:05:05,170 --> 00:05:06,530
the developers.

120
00:05:06,530 --> 00:05:08,530
And here's where we're
at with that.

121
00:05:08,530 --> 00:05:12,940
The first WebRTC support is now
shipping in Chrome 21, the

122
00:05:12,940 --> 00:05:14,620
current Chrome Dev track.

123
00:05:14,620 --> 00:05:16,390
And also in Opera 12.

124
00:05:16,390 --> 00:05:18,970
We're expecting to have Firefox
join us before the end

125
00:05:18,970 --> 00:05:20,520
of the year.

126
00:05:20,520 --> 00:05:24,240
We've also brought WebRTC
support to Internet Explorer

127
00:05:24,240 --> 00:05:25,650
via ChromeFrame.

128
00:05:25,650 --> 00:05:28,470
And so we'll soon have
support across

129
00:05:28,470 --> 00:05:31,780
almost all desktop browsers.

130
00:05:31,780 --> 00:05:34,130
As this technology stabilizes,
we're also going to see web

131
00:05:34,130 --> 00:05:37,480
WebRTC start to appear in the
various mobile browsers.

132
00:05:37,480 --> 00:05:41,790
And for those building native
applications, either on

133
00:05:41,790 --> 00:05:45,030
desktop or mobile, we have
native versions of the WebRTC

134
00:05:45,030 --> 00:05:47,110
stack that are fully compatible
with their web

135
00:05:47,110 --> 00:05:48,360
counterparts.

136
00:05:48,360 --> 00:05:50,280

137
00:05:50,280 --> 00:05:53,270
So the functionality the WebRTC
offers falls into three

138
00:05:53,270 --> 00:05:55,180
categories.

139
00:05:55,180 --> 00:05:59,840
The first, MediaStreams, also
known as get user media, is

140
00:05:59,840 --> 00:06:02,450
about getting access to the
user's camera and mic.

141
00:06:02,450 --> 00:06:03,800
There are a lot of cool
apps that can be

142
00:06:03,800 --> 00:06:06,190
built with just this.

143
00:06:06,190 --> 00:06:08,970
Next the technology called
PeerConnection.

144
00:06:08,970 --> 00:06:11,830
This is the engine behind making
high quality peer to

145
00:06:11,830 --> 00:06:15,850
peer voice and video
calls on the web.

146
00:06:15,850 --> 00:06:17,280
Last is a new bit of
functionality called

147
00:06:17,280 --> 00:06:18,160
DataChannels.

148
00:06:18,160 --> 00:06:21,630
It's so new, the spec for this
hasn't fully stabilized yet.

149
00:06:21,630 --> 00:06:23,480
But it has incredible
potential.

150
00:06:23,480 --> 00:06:28,670
The ability for any web app to
be a P2P app, to exchange

151
00:06:28,670 --> 00:06:31,620
application data peer to peer.

152
00:06:31,620 --> 00:06:36,045
Now let's take a look at
each one of these.

153
00:06:36,045 --> 00:06:39,040
Now, if you're following along
at home, and you want to try

154
00:06:39,040 --> 00:06:41,600
out the things about the show,
and you're running Chrome, you

155
00:06:41,600 --> 00:06:43,860
want to turn on the flags to
enable MediaStreams and

156
00:06:43,860 --> 00:06:45,470
PeerConnection.

157
00:06:45,470 --> 00:06:50,430
If you go to About Flags in your
Chrome build, you'll see

158
00:06:50,430 --> 00:06:51,905
these options in a list.

159
00:06:51,905 --> 00:06:54,330
And you turn on MediaStream
and PeerConnection.

160
00:06:54,330 --> 00:06:57,510
In the Dev channel on Chrome
21, you won't see a

161
00:06:57,510 --> 00:07:00,800
MediaStream option, because
it's now on by default.

162
00:07:00,800 --> 00:07:02,420
And if you don't want to turn
this on for your existing

163
00:07:02,420 --> 00:07:05,850
version of Chrome, you can
download Google Chrome Canary

164
00:07:05,850 --> 00:07:07,810
and run it side by
side with your

165
00:07:07,810 --> 00:07:09,060
existing version of Chrome.

166
00:07:09,060 --> 00:07:11,452

167
00:07:11,452 --> 00:07:13,420
So first up, MediaStreams.

168
00:07:13,420 --> 00:07:17,170

169
00:07:17,170 --> 00:07:20,500
A MediaStream represents a media
source, and can contain

170
00:07:20,500 --> 00:07:24,130
multiple media tracks that
can be of various types.

171
00:07:24,130 --> 00:07:27,370
So for example, if we get a
MediaStream for the user's

172
00:07:27,370 --> 00:07:30,890
webcam and mic, we'll have a
single stream, but a track for

173
00:07:30,890 --> 00:07:35,020
video, and a track for audio, as
shown in the diagram here.

174
00:07:35,020 --> 00:07:37,540
Now, in a video conference,
we could have multiple

175
00:07:37,540 --> 00:07:39,200
MediaStreams.

176
00:07:39,200 --> 00:07:42,280
And one MediaStream would exist
for each participant,

177
00:07:42,280 --> 00:07:45,680
each one with an audio
and video track.

178
00:07:45,680 --> 00:07:48,270
Now, once we have a MediaStream
we need a way to

179
00:07:48,270 --> 00:07:49,520
actually play it out.

180
00:07:49,520 --> 00:07:52,390
And fortunately, we have an
easy way to play audio and

181
00:07:52,390 --> 00:07:54,930
video in HTML via
the aptly named,

182
00:07:54,930 --> 00:07:57,070
audio and video elements.

183
00:07:57,070 --> 00:07:59,470
Now, in order to plug a
MediaStream into these

184
00:07:59,470 --> 00:08:03,050
elements, we first need a way
to get a URL that references

185
00:08:03,050 --> 00:08:04,200
the MediaStream.

186
00:08:04,200 --> 00:08:07,700
Fortunately, there's a method
called create object URL that

187
00:08:07,700 --> 00:08:09,500
does just that.

188
00:08:09,500 --> 00:08:13,370
Plug that URL into a tag, and
then media will start to play.

189
00:08:13,370 --> 00:08:15,910
Now lastly, how do we get
the MediaStream for

190
00:08:15,910 --> 00:08:16,910
the webcam and mic?

191
00:08:16,910 --> 00:08:20,620
So there's a new API called
getUserMedia.

192
00:08:20,620 --> 00:08:23,770
In Chrome, it's prefixed
as WebKit getUserMedia.

193
00:08:23,770 --> 00:08:25,420
And the API is async.

194
00:08:25,420 --> 00:08:28,740
So you call it, it prompts the
user for permission to access

195
00:08:28,740 --> 00:08:29,270
their devices.

196
00:08:29,270 --> 00:08:30,740
We spend a lot of time worrying

197
00:08:30,740 --> 00:08:32,409
about privacy and security.

198
00:08:32,409 --> 00:08:35,630
And that gives you back a
MediaStream via callback once

199
00:08:35,630 --> 00:08:36,880
it's successful.

200
00:08:36,880 --> 00:08:39,240

201
00:08:39,240 --> 00:08:42,230
So here's that all
put together.

202
00:08:42,230 --> 00:08:47,595
Get user media, get a callback,
create URL, stuff it

203
00:08:47,595 --> 00:08:49,500
in a video tag.

204
00:08:49,500 --> 00:08:50,750
So let's see that in action.

205
00:08:50,750 --> 00:08:55,030

206
00:08:55,030 --> 00:08:57,310
So here we get prompted
for our camera.

207
00:08:57,310 --> 00:09:00,160
I'll pick my good camera
right here.

208
00:09:00,160 --> 00:09:04,140
And there it is.

209
00:09:04,140 --> 00:09:06,570
Webcam access right
in the browser.

210
00:09:06,570 --> 00:09:07,820
Pretty cool.

211
00:09:07,820 --> 00:09:11,610

212
00:09:11,610 --> 00:09:16,980
So now let's jazz it
up a little bit.

213
00:09:16,980 --> 00:09:18,900
So the first thing that
everybody does with

214
00:09:18,900 --> 00:09:21,640
getUserMedia is to make
a Photo Booth app.

215
00:09:21,640 --> 00:09:24,060
And we're not going to
be any exception.

216
00:09:24,060 --> 00:09:26,820
So let's add a button so that we
can draw the current video

217
00:09:26,820 --> 00:09:30,330
frame directly onto a campus,
just like a camera.

218
00:09:30,330 --> 00:09:32,980
So let's try that out.

219
00:09:32,980 --> 00:09:35,030
So here's our next sample.

220
00:09:35,030 --> 00:09:35,520
Get prompted.

221
00:09:35,520 --> 00:09:37,550
This time I'm going to tell it
to remember it, so I don't

222
00:09:37,550 --> 00:09:38,800
want you to do this again.

223
00:09:38,800 --> 00:09:41,860

224
00:09:41,860 --> 00:09:47,240
OK, and so give a big thumbs
up for the camera here.

225
00:09:47,240 --> 00:09:48,690
And there's our Photo Booth.

226
00:09:48,690 --> 00:09:54,920

227
00:09:54,920 --> 00:09:57,610
So of course, all good Photo
Booths need some

228
00:09:57,610 --> 00:09:59,320
sort of video effects.

229
00:09:59,320 --> 00:10:02,180
The web platform gives us some
great tools to do this.

230
00:10:02,180 --> 00:10:06,170
With CSS, we can apply a style
to any visual element, like a

231
00:10:06,170 --> 00:10:08,500
video tag or a canvas.

232
00:10:08,500 --> 00:10:11,950
So here, we can apply a black
and white effect, this built

233
00:10:11,950 --> 00:10:14,660
in webkit gray scale CSS.

234
00:10:14,660 --> 00:10:16,840
And so when the button is
clicked, we're going to apply

235
00:10:16,840 --> 00:10:20,430
that CSS class to the
video element.

236
00:10:20,430 --> 00:10:21,870
So I've made a demo.

237
00:10:21,870 --> 00:10:23,620
And I've got a couple more
effects in here.

238
00:10:23,620 --> 00:10:25,160
So let me show them
to you now.

239
00:10:25,160 --> 00:10:27,740

240
00:10:27,740 --> 00:10:28,370
So I start up.

241
00:10:28,370 --> 00:10:31,370
And since I've remembered the
preference, it doesn't need to

242
00:10:31,370 --> 00:10:32,510
prompt me again.

243
00:10:32,510 --> 00:10:35,320
So let me try, we got
sepia tone here.

244
00:10:35,320 --> 00:10:37,925
And let's see, there's blur.

245
00:10:37,925 --> 00:10:38,910
And there's black and white.

246
00:10:38,910 --> 00:10:40,765
And I like black and white,
it looks real serious.

247
00:10:40,765 --> 00:10:43,380

248
00:10:43,380 --> 00:10:45,660
So there's a lot of cool
stuff you can do

249
00:10:45,660 --> 00:10:46,910
just with these things.

250
00:10:46,910 --> 00:10:49,290

251
00:10:49,290 --> 00:10:53,760
Now, that's what you can do
with a few lines of code.

252
00:10:53,760 --> 00:10:56,800
But I want to show you now
a complete Photo Booth

253
00:10:56,800 --> 00:10:58,670
application that uses
this technology.

254
00:10:58,670 --> 00:11:00,940
And the app I'm about to show
you is called Webcam Toy.

255
00:11:00,940 --> 00:11:05,000
And it's written by a guy named
Paul Neave, who got

256
00:11:05,000 --> 00:11:08,200
involved with WebRTC in the
very, very beginning.

257
00:11:08,200 --> 00:11:12,400
And so this thing uses Canvas
and WebGL pixel shaders to do

258
00:11:12,400 --> 00:11:13,540
some really amazing effects.

259
00:11:13,540 --> 00:11:16,030
There's over 100 effects
in this app.

260
00:11:16,030 --> 00:11:17,480
So there's some really
cool ones.

261
00:11:17,480 --> 00:11:18,720
Like, let me show you.

262
00:11:18,720 --> 00:11:19,940
This one's one of my
favorites here.

263
00:11:19,940 --> 00:11:23,450
Snow, it comes down and it sort
of builds up and stuff.

264
00:11:23,450 --> 00:11:25,510
And you can kind of clear
it off and stuff.

265
00:11:25,510 --> 00:11:26,510
It's really cool.

266
00:11:26,510 --> 00:11:29,000
And let's see, what else?

267
00:11:29,000 --> 00:11:32,140
The sketch one, this is also
one of my favorites.

268
00:11:32,140 --> 00:11:35,090
But what I really want to do is
I'm going to take a picture

269
00:11:35,090 --> 00:11:37,640
this room so I can remember
this moment here.

270
00:11:37,640 --> 00:11:39,890
All right, what's
a good effect?

271
00:11:39,890 --> 00:11:41,140
I like this one.

272
00:11:41,140 --> 00:11:46,002

273
00:11:46,002 --> 00:11:48,970
[CAMERA SHUTTER SOUND]

274
00:11:48,970 --> 00:11:53,010
JUSTIN UBERTI: All right,
immortalized forever.

275
00:11:53,010 --> 00:11:56,700
OK, so one other thing that Paul
has done, though, is he's

276
00:11:56,700 --> 00:12:00,330
wired getUserMedia to do
real-time face recognition in

277
00:12:00,330 --> 00:12:01,580
JavaScript.

278
00:12:01,580 --> 00:12:10,500

279
00:12:10,500 --> 00:12:13,660
So here we have real-time face
detection running in

280
00:12:13,660 --> 00:12:14,610
JavaScript.

281
00:12:14,610 --> 00:12:17,760
Now, I never thought I would
be saying those words.

282
00:12:17,760 --> 00:12:21,530
But here it is, as long as
I look at the camera.

283
00:12:21,530 --> 00:12:23,730
So this kind of gives
a new meaning to

284
00:12:23,730 --> 00:12:26,320
Chrome's incognito mode.

285
00:12:26,320 --> 00:12:29,670
So as you can see, some amazing
things are possible

286
00:12:29,670 --> 00:12:32,170
when we combine WebRTC with the
rest of the web platform.

287
00:12:32,170 --> 00:12:39,390

288
00:12:39,390 --> 00:12:43,230
OK, so that's how we get
access to devices.

289
00:12:43,230 --> 00:12:45,290
Now PeerConnection Connection
will let us take those

290
00:12:45,290 --> 00:12:47,310
MediaStreams and send
them across the

291
00:12:47,310 --> 00:12:49,140
internet peer to peer.

292
00:12:49,140 --> 00:12:51,860

293
00:12:51,860 --> 00:12:56,643
So PeerConnection, as its name
indicates, is the API they use

294
00:12:56,643 --> 00:12:58,440
to set up peer to
peer sessions.

295
00:12:58,440 --> 00:13:01,270
And it handles all the tricky
parts you need to establish a

296
00:13:01,270 --> 00:13:05,390
connection and run audio/video
over it, establishing the P2P

297
00:13:05,390 --> 00:13:08,820
link, managing the various
audio and video codecs,

298
00:13:08,820 --> 00:13:11,080
encryption, tuning the
audio/video stream to make

299
00:13:11,080 --> 00:13:14,570
best use of the available
bandwidth.

300
00:13:14,570 --> 00:13:17,740
But before we get into how
PeerConnection works, let's

301
00:13:17,740 --> 00:13:20,830
take a look at a typical voice
video application.

302
00:13:20,830 --> 00:13:23,350
I have Google Talk, let's
set up a call.

303
00:13:23,350 --> 00:13:27,040
So the app wants to be able to
send the media directly to the

304
00:13:27,040 --> 00:13:27,640
other side.

305
00:13:27,640 --> 00:13:30,090
But in order to do so, it needs
to establish the direct

306
00:13:30,090 --> 00:13:32,720
link and the details of how
the media should be sent.

307
00:13:32,720 --> 00:13:35,500
And the way it does that is sort
of by randevuing through

308
00:13:35,500 --> 00:13:39,560
the cloud by sending signaling
messages over its connection

309
00:13:39,560 --> 00:13:42,720
using a protocol like
XMPP or SIP.

310
00:13:42,720 --> 00:13:45,140
And these messages are relayed
to the other side.

311
00:13:45,140 --> 00:13:47,890
This exchange of parameters
allows both sides to

312
00:13:47,890 --> 00:13:52,690
successfully randevu and
establish the call.

313
00:13:52,690 --> 00:13:55,810
Now, what we could have just
taken that logic and stuffed

314
00:13:55,810 --> 00:13:56,910
it into the browser.

315
00:13:56,910 --> 00:13:58,895
The app would just tell the
browser where to connect to

316
00:13:58,895 --> 00:14:01,930
and to establish a SIP or XMPP
connection, just like a

317
00:14:01,930 --> 00:14:03,430
desktop app.

318
00:14:03,430 --> 00:14:07,290
But this isn't my makes sense
for a couple reasons.

319
00:14:07,290 --> 00:14:08,740
The app already has
a connection to

320
00:14:08,740 --> 00:14:11,266
the cloud using HTTP.

321
00:14:11,266 --> 00:14:14,010
And if we bake the signaling
protocol into the browser,

322
00:14:14,010 --> 00:14:17,010
we'd have to pick one that
everybody could agree on.

323
00:14:17,010 --> 00:14:19,010
That doesn't seem too likely,
given the various apps that

324
00:14:19,010 --> 00:14:20,560
are out there.

325
00:14:20,560 --> 00:14:22,790
And lastly, this connection
would have to deal with all

326
00:14:22,790 --> 00:14:27,640
the proxy and Firewall issues
that HTTP has already solved.

327
00:14:27,640 --> 00:14:29,000
So we didn't do this.

328
00:14:29,000 --> 00:14:30,780
What did we do?

329
00:14:30,780 --> 00:14:33,040
So we have an approach
that's called JSEP--

330
00:14:33,040 --> 00:14:36,050
JavaScript Session Establishment
Protocol.

331
00:14:36,050 --> 00:14:38,280
And we thought, let's
put the minimum we

332
00:14:38,280 --> 00:14:39,620
need into the browser.

333
00:14:39,620 --> 00:14:42,620
In 2012, that's peer to peer
networking, codecs, and

334
00:14:42,620 --> 00:14:43,450
encryption.

335
00:14:43,450 --> 00:14:44,870
And let the app do
all the rest.

336
00:14:44,870 --> 00:14:47,160
The app can manage all the call
setup, using whatever

337
00:14:47,160 --> 00:14:49,000
mechanism it wants.

338
00:14:49,000 --> 00:14:51,450
The app will simply tell the
browser about the parameters

339
00:14:51,450 --> 00:14:54,440
it wants to use for the call
using things we call session

340
00:14:54,440 --> 00:14:56,370
descriptions.

341
00:14:56,370 --> 00:14:58,910
As long as the app has some
way to exchange session

342
00:14:58,910 --> 00:15:01,980
descriptions with the other
side, it can do this any way

343
00:15:01,980 --> 00:15:03,230
that it wants to.

344
00:15:03,230 --> 00:15:05,560

345
00:15:05,560 --> 00:15:11,500
So for example, we could use
App Engine and use XML HTTP

346
00:15:11,500 --> 00:15:14,675
Request to post the session
descriptions using an adjacent

347
00:15:14,675 --> 00:15:16,260
encoding to App Engine.

348
00:15:16,260 --> 00:15:18,940
And have App Engine deliver them
to the remote side using

349
00:15:18,940 --> 00:15:22,670
the App Engine channel API.

350
00:15:22,670 --> 00:15:25,850
Or we could actually implement
the SIP protocol in

351
00:15:25,850 --> 00:15:28,800
JavaScript, convert the session
descriptions to SIP

352
00:15:28,800 --> 00:15:31,180
messages and send them
to existing SIP

353
00:15:31,180 --> 00:15:32,460
equipment out there.

354
00:15:32,460 --> 00:15:34,730
And so there's a ton of existing
SIP equipment, the

355
00:15:34,730 --> 00:15:37,200
phone network, soft switches,
existing enterprise video

356
00:15:37,200 --> 00:15:38,310
conferencing equipment.

357
00:15:38,310 --> 00:15:42,760
And people are already using
this today to have SIP Interop

358
00:15:42,760 --> 00:15:46,110
with WebRTC without forcing
WebRTC to have SIP built in.

359
00:15:46,110 --> 00:15:48,680

360
00:15:48,680 --> 00:15:52,160
So the abstract PeerConnection
API allows us to handle either

361
00:15:52,160 --> 00:15:54,570
of these cases, along with a
whole set of others that I

362
00:15:54,570 --> 00:15:56,100
haven't mentioned.

363
00:15:56,100 --> 00:15:59,740
Now, the basic thing that a
PeerConnection needs is in

364
00:15:59,740 --> 00:16:02,720
local session description,
which holds the local

365
00:16:02,720 --> 00:16:05,910
parameters for the call in the
remote session description,

366
00:16:05,910 --> 00:16:08,030
which indicates the
remote parameters.

367
00:16:08,030 --> 00:16:12,110
It also needs the transport
candidates, which are the IP

368
00:16:12,110 --> 00:16:15,420
addresses and ports that the
remote side is reachable at.

369
00:16:15,420 --> 00:16:17,070
Sometimes these are included
within the session

370
00:16:17,070 --> 00:16:18,950
description.

371
00:16:18,950 --> 00:16:21,790
Now, I'm going to walk through
a call setup, and show how

372
00:16:21,790 --> 00:16:23,760
these parameters
are exchanged.

373
00:16:23,760 --> 00:16:27,890
One thing to note, the initial
parameters sent by the caller

374
00:16:27,890 --> 00:16:30,760
specify everything that a
caller is capable of.

375
00:16:30,760 --> 00:16:32,730
And we call that an offer.

376
00:16:32,730 --> 00:16:36,180
The response from the callee,
which indicates the negotiated

377
00:16:36,180 --> 00:16:38,500
or selected parameters,
is called an answer.

378
00:16:38,500 --> 00:16:49,990

379
00:16:49,990 --> 00:16:51,540
So here's the first thing.

380
00:16:51,540 --> 00:16:54,380
The app creates the local
session description, the

381
00:16:54,380 --> 00:16:58,680
offer, passes into the
PeerConnection API, and sends

382
00:16:58,680 --> 00:17:03,390
it to the remote side using
whatever mechanism it wants.

383
00:17:03,390 --> 00:17:07,000
The caller gets it and gives it
to the PeerConnection API

384
00:17:07,000 --> 00:17:09,869
as the remote description.

385
00:17:09,869 --> 00:17:13,119
Then, assuming that the callee
accepts the call, generates

386
00:17:13,119 --> 00:17:16,319
their own session description,
passes it into PeerConnection,

387
00:17:16,319 --> 00:17:19,569
and sends it back to the
caller as an answer.

388
00:17:19,569 --> 00:17:23,050
The caller gets that answer and
gives it to PeerConnection

389
00:17:23,050 --> 00:17:24,300
as a receive session
description.

390
00:17:24,300 --> 00:17:26,900

391
00:17:26,900 --> 00:17:29,050
Now, at this point, the browser
has everything it

392
00:17:29,050 --> 00:17:31,960
needs to establish the call, the
local session description,

393
00:17:31,960 --> 00:17:33,880
the remote session description,
the transport

394
00:17:33,880 --> 00:17:39,320
candidates, the P2P link gets
established, and media flows.

395
00:17:39,320 --> 00:17:42,750
So let's look at what this
looks like in code.

396
00:17:42,750 --> 00:17:45,950
The caller creates a
PeerConnection, plugs a

397
00:17:45,950 --> 00:17:50,000
MediaStream into it, which it
got from the getUserMedia API

398
00:17:50,000 --> 00:17:51,490
via add stream.

399
00:17:51,490 --> 00:17:54,770
It then creates an offer, plugs
it in, and sends it off

400
00:17:54,770 --> 00:17:56,620
to the callee.

401
00:17:56,620 --> 00:17:59,880
When the callee gets it, over
here on the right, it creates

402
00:17:59,880 --> 00:18:02,860
a PeerConnection, stuffs in
the offer via set remote

403
00:18:02,860 --> 00:18:05,660
description, and then creates
its own session description as

404
00:18:05,660 --> 00:18:10,230
an answer that it can send
back to the caller.

405
00:18:10,230 --> 00:18:13,110
The caller then gets its answer
on the left, sets call

406
00:18:13,110 --> 00:18:15,670
set remote description with the
received answer, and the

407
00:18:15,670 --> 00:18:16,920
set up is complete.

408
00:18:16,920 --> 00:18:20,700

409
00:18:20,700 --> 00:18:23,290
So let's see how this
looks like in code.

410
00:18:23,290 --> 00:18:25,690
We're going to do the
offer/answer dance here in a

411
00:18:25,690 --> 00:18:28,230
single web page with two
PeerConnections.

412
00:18:28,230 --> 00:18:31,060
Instead of sending these
messages across the internet,

413
00:18:31,060 --> 00:18:33,100
we're going to just stuff them
directly into the appropriate

414
00:18:33,100 --> 00:18:36,140
PeerConnection So let's
try this out.

415
00:18:36,140 --> 00:18:40,440

416
00:18:40,440 --> 00:18:41,690
Still like this incognito
mode.

417
00:18:41,690 --> 00:18:49,720

418
00:18:49,720 --> 00:18:50,640
OK.

419
00:18:50,640 --> 00:18:52,600
So we start up the camera.

420
00:18:52,600 --> 00:18:59,140

421
00:18:59,140 --> 00:19:01,180
And now, when we hit the call
button, we're going to spin up

422
00:19:01,180 --> 00:19:04,710
all the codec, P2P, crypto,
all that sort of stuff.

423
00:19:04,710 --> 00:19:07,750
And we should see the video
appear in the panel on the

424
00:19:07,750 --> 00:19:11,650
right as what the remote
user would see.

425
00:19:11,650 --> 00:19:13,783
Bang, there it is.

426
00:19:13,783 --> 00:19:15,050
Now, let me show
you that again.

427
00:19:15,050 --> 00:19:18,800
I'm going to hang it
up and call again.

428
00:19:18,800 --> 00:19:20,900
And there it goes.

429
00:19:20,900 --> 00:19:23,590
So you'll see that we have
this functionality.

430
00:19:23,590 --> 00:19:25,550
And as long as it's sending
session descriptions back and

431
00:19:25,550 --> 00:19:33,030
forth, the rest of it pretty
much manages itself.

432
00:19:33,030 --> 00:19:35,795
Now, that's kind of cheating.

433
00:19:35,795 --> 00:19:38,710
You know, passing the data back
and forth in a single web

434
00:19:38,710 --> 00:19:40,960
page isn't really that
interesting from

435
00:19:40,960 --> 00:19:41,760
a video call scenario.

436
00:19:41,760 --> 00:19:44,280
We want to call someone on the
other side of the planet, not

437
00:19:44,280 --> 00:19:45,390
in the same web page.

438
00:19:45,390 --> 00:19:48,150
So how are we to do This Well,
in order to make this into a

439
00:19:48,150 --> 00:19:51,040
real video calling app, we need
to send those session

440
00:19:51,040 --> 00:19:53,280
descriptions across
the internet.

441
00:19:53,280 --> 00:19:54,930
Now, let's look at how
we can do that.

442
00:19:54,930 --> 00:19:58,180

443
00:19:58,180 --> 00:20:00,440
So it's really easy
to send a session

444
00:20:00,440 --> 00:20:02,060
description to the cloud.

445
00:20:02,060 --> 00:20:04,340
We just make it into a string,
and shoot it off

446
00:20:04,340 --> 00:20:06,936
over XML HTTP Request.

447
00:20:06,936 --> 00:20:09,160
But how can we receive them?

448
00:20:09,160 --> 00:20:12,290
Especially when this is a
real-time application.

449
00:20:12,290 --> 00:20:13,630
The caller doesn't want
to sit there forever

450
00:20:13,630 --> 00:20:15,060
waiting for the callee.

451
00:20:15,060 --> 00:20:17,790
We don't want to spend a
lot of time polling.

452
00:20:17,790 --> 00:20:18,960
What can we do?

453
00:20:18,960 --> 00:20:21,750
Well, App Engine gives us
a great tool for this.

454
00:20:21,750 --> 00:20:25,480
The Channel API provides an easy
to use, server to client

455
00:20:25,480 --> 00:20:28,600
signaling path for pushing
session descriptions from the

456
00:20:28,600 --> 00:20:30,450
server to the client.

457
00:20:30,450 --> 00:20:33,810
And App Engine takes care
of all the details.

458
00:20:33,810 --> 00:20:36,910
No matter how many users you
have, or where users are in

459
00:20:36,910 --> 00:20:39,290
the world, you can use
the same simple API

460
00:20:39,290 --> 00:20:40,540
to send down messages.

461
00:20:40,540 --> 00:20:44,080

462
00:20:44,080 --> 00:20:45,195
So here's how it works.

463
00:20:45,195 --> 00:20:48,260
The first thing you do is
establish a channel.

464
00:20:48,260 --> 00:20:50,530
You can do this when serving
the web page to eliminate a

465
00:20:50,530 --> 00:20:51,470
round trip.

466
00:20:51,470 --> 00:20:54,670
So in the server, you simply
create a Channel API token and

467
00:20:54,670 --> 00:20:57,720
send it down in the
web page response.

468
00:20:57,720 --> 00:21:00,620
The app then uses the JavaScript
API with that token

469
00:21:00,620 --> 00:21:03,420
to bring up the back channel,
and you're ready to rock.

470
00:21:03,420 --> 00:21:05,310
You can send messages
from your server

471
00:21:05,310 --> 00:21:08,010
down to your client.

472
00:21:08,010 --> 00:21:12,100
So here we have Client B that
wants to send a message and

473
00:21:12,100 --> 00:21:15,450
link the session description
to Client A. It does so

474
00:21:15,450 --> 00:21:16,020
typically [? in the ?]

475
00:21:16,020 --> 00:21:19,420
POST using XML HTTP
Request to get the

476
00:21:19,420 --> 00:21:21,720
message up to App Engine.

477
00:21:21,720 --> 00:21:23,765
And then it codes an identifier
to indicate who it

478
00:21:23,765 --> 00:21:24,550
should be sent to.

479
00:21:24,550 --> 00:21:26,970
Now, your app can use the
identifier to find the right

480
00:21:26,970 --> 00:21:29,410
channel instance on
the server side.

481
00:21:29,410 --> 00:21:31,330
And once it does that, you
simply call [? send ?]

482
00:21:31,330 --> 00:21:31,775
the channel.

483
00:21:31,775 --> 00:21:34,680
And it gets pushed down to
Client A who receives it in a

484
00:21:34,680 --> 00:21:37,250
JavaScript callback,
super easy.

485
00:21:37,250 --> 00:21:40,470

486
00:21:40,470 --> 00:21:44,500
So here's a snippet that shows
how this all works.

487
00:21:44,500 --> 00:21:48,140
At the top, the client brings up
the back channel using the

488
00:21:48,140 --> 00:21:49,770
App Engine API.

489
00:21:49,770 --> 00:21:53,520
Then, when it gets an incoming
call message in its callback,

490
00:21:53,520 --> 00:21:56,610
we can set the remote and local
descriptions, create an

491
00:21:56,610 --> 00:21:59,400
answer, and then shoot
that back using XHR.

492
00:21:59,400 --> 00:22:04,340

493
00:22:04,340 --> 00:22:07,790
So these are some great little
examples to sort of show the

494
00:22:07,790 --> 00:22:09,970
basics of the API.

495
00:22:09,970 --> 00:22:13,440
But we also want to have a
complete video calling

496
00:22:13,440 --> 00:22:16,410
application, a reference sample
application, where we

497
00:22:16,410 --> 00:22:20,140
can show developers the
best ways to bring

498
00:22:20,140 --> 00:22:21,490
this stuff all together.

499
00:22:21,490 --> 00:22:23,670
And we also want it to be the
kind of application that we

500
00:22:23,670 --> 00:22:26,840
can use in our daily work, not
just a sample app, something

501
00:22:26,840 --> 00:22:29,910
that will be a full-fledged
reference application.

502
00:22:29,910 --> 00:22:32,730
So we created AppRTC.

503
00:22:32,730 --> 00:22:35,830
It runs on App Engine using
things like Channel API and

504
00:22:35,830 --> 00:22:40,040
Data Store, and shows how to use
the WebRTC APIs, handling

505
00:22:40,040 --> 00:22:43,760
session descriptions, making
call setup fast, and showing

506
00:22:43,760 --> 00:22:45,130
NAT Traversal works.

507
00:22:45,130 --> 00:22:47,725
And every AppRTC call
is fully encrypted.

508
00:22:47,725 --> 00:22:51,040

509
00:22:51,040 --> 00:22:54,940
Now, I really want to
show this to you.

510
00:22:54,940 --> 00:22:57,640
So we've got some people
on the team.

511
00:22:57,640 --> 00:22:59,800
And they've been working
really hard on

512
00:22:59,800 --> 00:23:03,250
some updates to AppRTC.

513
00:23:03,250 --> 00:23:06,000
Now, I want to just sort of
check in with them real quick

514
00:23:06,000 --> 00:23:09,620
and make sure that they're not
getting too stressed out.

515
00:23:09,620 --> 00:23:11,150
So let's do that now.

516
00:23:11,150 --> 00:23:23,330

517
00:23:23,330 --> 00:23:24,580
OK.

518
00:23:24,580 --> 00:23:33,130

519
00:23:33,130 --> 00:23:34,980
Hey, Ray.

520
00:23:34,980 --> 00:23:37,290
You look pretty relaxed there.

521
00:23:37,290 --> 00:23:40,560
Did you get that work done
I wanted you to do?

522
00:23:40,560 --> 00:23:41,945
RAY: Yep, yep, sure did.

523
00:23:41,945 --> 00:23:44,830
WebRTC and App Engine
took care of the

524
00:23:44,830 --> 00:23:45,630
most complicated stuff.

525
00:23:45,630 --> 00:23:49,970
So I'm done, Justin.

526
00:23:49,970 --> 00:23:52,560
JUSTIN UBERTI: Well, I mean,
let me say, it looks great.

527
00:23:52,560 --> 00:23:57,630
I mean, not just the app,
but also your pool.

528
00:23:57,630 --> 00:24:00,770
You know, I wish I could
swing by later.

529
00:24:00,770 --> 00:24:03,510
Anyway, I've got to get
back to the session.

530
00:24:03,510 --> 00:24:04,600
It's going great.

531
00:24:04,600 --> 00:24:07,090
And I'll let you get
back to relaxing.

532
00:24:07,090 --> 00:24:08,190
Catch you later, Ray.

533
00:24:08,190 --> 00:24:09,440
RAY: See you, Justin.

534
00:24:09,440 --> 00:24:12,750

535
00:24:12,750 --> 00:24:18,030
[APPLAUSE]

536
00:24:18,030 --> 00:24:20,860
JUSTIN UBERTI: So that's the
kind of quality that you can

537
00:24:20,860 --> 00:24:22,660
accomplish with WebRTC.

538
00:24:22,660 --> 00:24:25,940
Real calls across the
internet, right

539
00:24:25,940 --> 00:24:27,190
from your web browser.

540
00:24:27,190 --> 00:24:30,760

541
00:24:30,760 --> 00:24:34,490
OK, so we just showed how
to send audio and

542
00:24:34,490 --> 00:24:36,040
video peer to peer.

543
00:24:36,040 --> 00:24:38,710
But what if we just
want to send data?

544
00:24:38,710 --> 00:24:40,120
Well, enter DataChannels.

545
00:24:40,120 --> 00:24:42,820

546
00:24:42,820 --> 00:24:45,720
So DataChannels designed to
allow apps to exchange

547
00:24:45,720 --> 00:24:49,100
arbitrary application data
with low latency, high

548
00:24:49,100 --> 00:24:52,710
throughput and message rate,
and optionally unreliable

549
00:24:52,710 --> 00:24:54,950
semantics so you keep
chugging, even

550
00:24:54,950 --> 00:24:56,620
if you lose a packet.

551
00:24:56,620 --> 00:24:58,530
Now, there are lots of great
real world use cases that

552
00:24:58,530 --> 00:25:02,030
DataChannels are great for.

553
00:25:02,030 --> 00:25:04,770
If you have a game, and you want
to send the positions of

554
00:25:04,770 --> 00:25:07,240
bullets in a game, you don't
want to send that data over

555
00:25:07,240 --> 00:25:11,110
HTTP, to the server and back
with all the HTTP overhead.

556
00:25:11,110 --> 00:25:13,560
You can instead send it in a
very tight, efficient message

557
00:25:13,560 --> 00:25:15,910
over the peer to peer channel.

558
00:25:15,910 --> 00:25:19,270
For remote desktop apps, you can
do things like track the

559
00:25:19,270 --> 00:25:22,880
position of the mouse with
great responsiveness.

560
00:25:22,880 --> 00:25:24,700
And there's a lot of other
great examples.

561
00:25:24,700 --> 00:25:27,230
But one I particularly like
is the ability to create a

562
00:25:27,230 --> 00:25:29,720
secure, decentralized network.

563
00:25:29,720 --> 00:25:32,870
And you can imagine, in a place
were there's censorship

564
00:25:32,870 --> 00:25:35,630
of the internet, you could
provide this mechanism as a

565
00:25:35,630 --> 00:25:38,680
way where people can communicate
over a private

566
00:25:38,680 --> 00:25:39,930
encrypted channel.

567
00:25:39,930 --> 00:25:42,730

568
00:25:42,730 --> 00:25:47,330
So here are the key features
of the DataChannel.

569
00:25:47,330 --> 00:25:49,130
To set it up, we're going
to leverage the

570
00:25:49,130 --> 00:25:50,450
PeerConnection setup.

571
00:25:50,450 --> 00:25:52,350
You do this sort of offer/answer
dance.

572
00:25:52,350 --> 00:25:53,830
We'll get the channel
bootstrapped.

573
00:25:53,830 --> 00:25:55,840
But then you can create
multiple channels.

574
00:25:55,840 --> 00:25:59,670
And those channels can all be
either reliable or unreliable.

575
00:25:59,670 --> 00:26:02,990
In a game, you might want your
state updates to be reliable,

576
00:26:02,990 --> 00:26:06,930
but projectiles can be sent over
an unreliable channel.

577
00:26:06,930 --> 00:26:09,560
Security and congestion control
is built right in.

578
00:26:09,560 --> 00:26:11,720
The app gets this for free.

579
00:26:11,720 --> 00:26:14,910
And we've tried to make
developers lives easier by

580
00:26:14,910 --> 00:26:18,040
keeping a similar API
to WebSockets.

581
00:26:18,040 --> 00:26:21,460
So that code written to use a
WebSocket should work just as

582
00:26:21,460 --> 00:26:23,180
well when coupled with
a DataChannel.

583
00:26:23,180 --> 00:26:26,830

584
00:26:26,830 --> 00:26:31,520
So here's a simple usage
of DataChannels.

585
00:26:31,520 --> 00:26:34,270
We want to have two clients
exchanging data.

586
00:26:34,270 --> 00:26:36,060
They exchange session
descriptions to get the peer

587
00:26:36,060 --> 00:26:37,760
to peer link set up.

588
00:26:37,760 --> 00:26:39,430
And then, we're ready to go.

589
00:26:39,430 --> 00:26:40,210
We send the data.

590
00:26:40,210 --> 00:26:42,960
And it gets sent over the
internet using standard IETF

591
00:26:42,960 --> 00:26:47,270
protocols, SCTP, Datagram
TLS over UDP.

592
00:26:47,270 --> 00:26:50,410
It goes through a [? NAS ?],
it just works.

593
00:26:50,410 --> 00:26:53,700
This is going to be a
revolutionary technology.

594
00:26:53,700 --> 00:26:57,870
And here's what this
looks like in code.

595
00:26:57,870 --> 00:26:59,320
It's really simple.

596
00:26:59,320 --> 00:27:02,640
You just call on each side,
create DataChannel, you

597
00:27:02,640 --> 00:27:04,270
specify an identifier.

598
00:27:04,270 --> 00:27:07,240
This identifier is what allows
both channels to get connected

599
00:27:07,240 --> 00:27:11,820
together in the middle because
they're indicated by name.

600
00:27:11,820 --> 00:27:13,260
And then, once it's connected,
you just

601
00:27:13,260 --> 00:27:15,140
call/send on one side.

602
00:27:15,140 --> 00:27:17,440
And our message gets called on
the other side, just like

603
00:27:17,440 --> 00:27:19,150
WebSockets.

604
00:27:19,150 --> 00:27:21,480
Now, I wish I could show
this to you now.

605
00:27:21,480 --> 00:27:23,350
But as I mentioned before, we're
still finishing up the

606
00:27:23,350 --> 00:27:24,680
details of the spec.

607
00:27:24,680 --> 00:27:27,550
But expect to see this in Chrome
in the near future.

608
00:27:27,550 --> 00:27:30,960

609
00:27:30,960 --> 00:27:33,660
So you can also imagine
some more complicated

610
00:27:33,660 --> 00:27:36,160
topologies for this.

611
00:27:36,160 --> 00:27:39,150
If we want to distribute data
between multiple peers, we can

612
00:27:39,150 --> 00:27:41,960
create a mesh, where each
endpoint is connected to each

613
00:27:41,960 --> 00:27:43,130
other endpoint.

614
00:27:43,130 --> 00:27:45,760
If you're creating like a
multiplayer game, this is a

615
00:27:45,760 --> 00:27:49,300
really easy way to get
multiplayer functionality

616
00:27:49,300 --> 00:27:53,130
without having to have a big
server infrastructure.

617
00:27:53,130 --> 00:27:55,630
But you can also imagine some
other interesting things.

618
00:27:55,630 --> 00:27:58,100
You create a graph.

619
00:27:58,100 --> 00:28:00,900
And say you want to be able to
send down a lot of data from

620
00:28:00,900 --> 00:28:02,020
your service.

621
00:28:02,020 --> 00:28:05,830
Instead of having to send the
data n times by unicasting it

622
00:28:05,830 --> 00:28:10,290
to all your clients, you can
instead construct a tree, and

623
00:28:10,290 --> 00:28:14,960
use peer to peer to push the
data very efficient to all

624
00:28:14,960 --> 00:28:16,030
your clients.

625
00:28:16,030 --> 00:28:18,370
Since you control the
application, you can have the

626
00:28:18,370 --> 00:28:21,570
application take the data and
it's distributed to other

627
00:28:21,570 --> 00:28:23,570
peers that it might
be connected to.

628
00:28:23,570 --> 00:28:26,090
There will be some amazing
things that will be created as

629
00:28:26,090 --> 00:28:27,340
a result of this technology.

630
00:28:27,340 --> 00:28:30,280

631
00:28:30,280 --> 00:28:34,850
OK, so we went over a lot
of stuff really quickly.

632
00:28:34,850 --> 00:28:36,100
Let's review.

633
00:28:36,100 --> 00:28:42,630

634
00:28:42,630 --> 00:28:45,590
We're building real-time
communication into the fabric

635
00:28:45,590 --> 00:28:50,090
of the web, providing amazing
new voice, video, and peer to

636
00:28:50,090 --> 00:28:54,920
peer functionality in the open
web platform, and enabling the

637
00:28:54,920 --> 00:28:59,490
communications industry
to move at web speed.

638
00:28:59,490 --> 00:29:01,260
This is a really
exciting time.

639
00:29:01,260 --> 00:29:02,720
We're really excited
on the team.

640
00:29:02,720 --> 00:29:04,320
We can't wait to see the
apps you guys are

641
00:29:04,320 --> 00:29:05,570
going to build on this.

642
00:29:05,570 --> 00:29:07,660

643
00:29:07,660 --> 00:29:12,400
So MediaStreams are shipping
in Chrome 21.

644
00:29:12,400 --> 00:29:15,640
PeerConnection is in Chrome
20 behind a flag.

645
00:29:15,640 --> 00:29:17,540
But we're working hard to
try to stabilize it in

646
00:29:17,540 --> 00:29:20,020
time for Chrome 22.

647
00:29:20,020 --> 00:29:21,950
The DataChannel works is going
to follow along after that.

648
00:29:21,950 --> 00:29:24,930
And we expect to do this
by the end of the year.

649
00:29:24,930 --> 00:29:27,320
Opera is also shipping
MediaStreams now.

650
00:29:27,320 --> 00:29:30,470
And our friends at Mozilla, they
tell us they think that

651
00:29:30,470 --> 00:29:34,310
they get all this stuff done
by the end of the year.

652
00:29:34,310 --> 00:29:37,700
Now, for people using Internet
Explorer, we've got WebRTC

653
00:29:37,700 --> 00:29:38,860
running in ChromeFrame.

654
00:29:38,860 --> 00:29:41,030
And it works great.

655
00:29:41,030 --> 00:29:42,980
As we start to stabilize things,
we're also going to

656
00:29:42,980 --> 00:29:44,915
see stuff landing in
mobile browsers.

657
00:29:44,915 --> 00:29:47,580
And as I mentioned before, we
have native versions of the

658
00:29:47,580 --> 00:29:50,190
entire stack available for the
app builders out there.

659
00:29:50,190 --> 00:29:55,180

660
00:29:55,180 --> 00:29:58,415
So here's our resident Icelandic
team member, Tommy

661
00:29:58,415 --> 00:29:59,400
Gunnarsson.

662
00:29:59,400 --> 00:30:03,580
He's showing off AppRTC running
here in IE, courtesy

663
00:30:03,580 --> 00:30:05,290
of ChromeFrame.

664
00:30:05,290 --> 00:30:08,360
So for more information about
ChromeFrame you check it out

665
00:30:08,360 --> 00:30:10,590
at google.com/chromeframe.

666
00:30:10,590 --> 00:30:13,630
Now, incidentally, we might
be thinking, well what is

667
00:30:13,630 --> 00:30:14,760
Microsoft doing about
supporting

668
00:30:14,760 --> 00:30:16,190
this natively in IE?

669
00:30:16,190 --> 00:30:18,490
Well, I don't know for sure.

670
00:30:18,490 --> 00:30:21,540
But I saw a couple of WebRTC
related job postings show up

671
00:30:21,540 --> 00:30:23,630
on the Microsoft career
site in the past week.

672
00:30:23,630 --> 00:30:25,120
So I'm pretty sure
they're investing

673
00:30:25,120 --> 00:30:26,370
pretty heavily in this.

674
00:30:26,370 --> 00:30:29,230

675
00:30:29,230 --> 00:30:34,380
OK, so I'd like to show you
one more demo, or two more

676
00:30:34,380 --> 00:30:38,460
demos here of examples of what
third-party developers are

677
00:30:38,460 --> 00:30:40,025
doing with this technology.

678
00:30:40,025 --> 00:30:43,390
So the first is an application
called Twinsee.

679
00:30:43,390 --> 00:30:46,670
The team there has created a
WebRTC app that works on both

680
00:30:46,670 --> 00:30:48,610
web and on mobile.

681
00:30:48,610 --> 00:30:50,193
And I'm going to call them
up now using the app

682
00:30:50,193 --> 00:30:51,443
that they've built.

683
00:30:51,443 --> 00:31:23,900

684
00:31:23,900 --> 00:31:24,580
MALE SPEAKER: Hello.

685
00:31:24,580 --> 00:31:25,750
JUSTIN UBERTI: Hey, guys.

686
00:31:25,750 --> 00:31:29,880
You're live at Google
I/O 2012.

687
00:31:29,880 --> 00:31:31,130
MALE SPEAKER: Wow.

688
00:31:31,130 --> 00:31:34,540

689
00:31:34,540 --> 00:31:36,080
JUSTIN UBERTI: So tell me
about this app that

690
00:31:36,080 --> 00:31:38,180
you've built. .

691
00:31:38,180 --> 00:31:40,210
MALE SPEAKER: OK so let me
introduce ourselves.

692
00:31:40,210 --> 00:31:41,920
So I'm [? Michel Gien, ?]

693
00:31:41,920 --> 00:31:44,480
and I'm here with
[? Christian Giacomo. ?]

694
00:31:44,480 --> 00:31:48,310
And we founded Twinlife at the
beginning of this year.

695
00:31:48,310 --> 00:31:52,680
And the purpose of Twinlife
is connecting generations.

696
00:31:52,680 --> 00:31:57,730
So our focus right now is to
take Android tablets and smart

697
00:31:57,730 --> 00:32:02,130
TVs and make them usable by
older persons, so they can

698
00:32:02,130 --> 00:32:04,520
interact with their family,
their children and

699
00:32:04,520 --> 00:32:06,360
grandchildren.

700
00:32:06,360 --> 00:32:12,980
So our first building block is
this Twinsee service, which is

701
00:32:12,980 --> 00:32:17,710
made of an Android application,
using at the

702
00:32:17,710 --> 00:32:21,390
native WebRTC APIs,
which Christian

703
00:32:21,390 --> 00:32:22,860
integrated into Android.

704
00:32:22,860 --> 00:32:30,060
And web service, twinsee.net, to
connect users, whether they

705
00:32:30,060 --> 00:32:33,500
come from a Chrome browser, or
whether they come from a

706
00:32:33,500 --> 00:32:37,660
Twinsee application
on Android tablet.

707
00:32:37,660 --> 00:32:38,600
JUSTIN UBERTI: That's great.

708
00:32:38,600 --> 00:32:40,345
It feels like you guys
are right here in San

709
00:32:40,345 --> 00:32:41,800
Francisco with us.

710
00:32:41,800 --> 00:32:44,260
So when can I expect this
to be available?

711
00:32:44,260 --> 00:32:47,700

712
00:32:47,700 --> 00:32:50,760
MALE SPEAKER: Twinsee will be
available for public testing

713
00:32:50,760 --> 00:32:55,650
on the Android Market in
the August time frame.

714
00:32:55,650 --> 00:32:58,610
So I'll show you here
in the mirror.

715
00:32:58,610 --> 00:33:00,800
You can see that this
tablet we're using

716
00:33:00,800 --> 00:33:03,520
right now is Asus Prime.

717
00:33:03,520 --> 00:33:05,900
And so if you have any
questions, contact us at

718
00:33:05,900 --> 00:33:08,450
twinsee.net.

719
00:33:08,450 --> 00:33:10,180
JUSTIN UBERTI: OK, that
looks great, guys.

720
00:33:10,180 --> 00:33:12,470
MALE SPEAKER: I hope you're have
at Google I/O. I wish we

721
00:33:12,470 --> 00:33:14,860
were there.

722
00:33:14,860 --> 00:33:15,940
JUSTIN UBERTI: Looks
great, guys.

723
00:33:15,940 --> 00:33:17,070
Well, that's really exciting.

724
00:33:17,070 --> 00:33:18,750
I'll let you guys
get some sleep.

725
00:33:18,750 --> 00:33:21,612
Talk to you later.

726
00:33:21,612 --> 00:33:34,680
[APPLAUSE]

727
00:33:34,680 --> 00:33:35,580
JUSTIN UBERTI: OK.

728
00:33:35,580 --> 00:33:40,030
So the last thing I want to
show, I know a ton of you are

729
00:33:40,030 --> 00:33:43,630
using GitHub to host and
share your code.

730
00:33:43,630 --> 00:33:46,240
So that's why I'm really excited
to introduce this next

731
00:33:46,240 --> 00:33:50,690
app called GitTogether, which
brings real-time communication

732
00:33:50,690 --> 00:33:52,680
to the GitHub community.

733
00:33:52,680 --> 00:33:55,240
Now, the guys who built this
have been involved with WebRTC

734
00:33:55,240 --> 00:33:56,820
since the very beginning.

735
00:33:56,820 --> 00:33:58,170
Let's call them up now.

736
00:33:58,170 --> 00:34:00,990
And they can tell you about
how this works.

737
00:34:00,990 --> 00:34:03,910
These guys have been
working on this.

738
00:34:03,910 --> 00:34:06,380
They're creating not just an
application, but also a

739
00:34:06,380 --> 00:34:09,199
JavaScript framework that
allows a lot of

740
00:34:09,199 --> 00:34:11,920
simplifications to be done
for people who are WebRTC

741
00:34:11,920 --> 00:34:13,170
developers.

742
00:34:13,170 --> 00:34:17,100

743
00:34:17,100 --> 00:34:21,420
So that's everything for
WebRTC see today.

744
00:34:21,420 --> 00:34:23,800
We covered a lot of
stuff quickly.

745
00:34:23,800 --> 00:34:31,000
[APPLAUSE]

746
00:34:31,000 --> 00:34:32,170
JUSTIN UBERTI: Thank you.

747
00:34:32,170 --> 00:34:35,790
Oh, also, the GitTogether
is made by vline.com.

748
00:34:35,790 --> 00:34:38,969
Also, check out the Chrome
Developer sandbox.

749
00:34:38,969 --> 00:34:40,120
We've got some stuff
down there.

750
00:34:40,120 --> 00:34:42,969
There's a Voxeo, who is an
emergency response app being

751
00:34:42,969 --> 00:34:44,489
built using WebRTC.

752
00:34:44,489 --> 00:34:47,940
And we've also got a really
cool WebRTC based game

753
00:34:47,940 --> 00:34:48,380
called Who Am I?

754
00:34:48,380 --> 00:34:49,840
MIT

755
00:34:49,840 --> 00:34:50,790
Thank you all for coming.

756
00:34:50,790 --> 00:34:52,670
I'll be happy to answer any
questions that you might have.

757
00:34:52,670 --> 00:34:57,500

758
00:34:57,500 --> 00:35:01,120
Step up to the microphone, so
the video can record it.

759
00:35:01,120 --> 00:35:03,120
AUDIENCE: In a lot of your
slides, you had a dotted line

760
00:35:03,120 --> 00:35:06,340
between the two browsers
on the bottom.

761
00:35:06,340 --> 00:35:10,430
Is that an actual connection
somehow.

762
00:35:10,430 --> 00:35:13,210
I mean, if both of them are
behind a net firewall, how do

763
00:35:13,210 --> 00:35:16,250
you get the peer to peer
communication to go?

764
00:35:16,250 --> 00:35:19,110
Is there actually a server
there that's--

765
00:35:19,110 --> 00:35:22,480
JUSTIN UBERTI: So there's
a technology called ICE.

766
00:35:22,480 --> 00:35:25,240
And ICE is Interactive
Connectivity Establishment.

767
00:35:25,240 --> 00:35:28,120
And what it does is it basically
finds all the IP

768
00:35:28,120 --> 00:35:31,080
addresses that it can come up,
your local address, the

769
00:35:31,080 --> 00:35:34,425
address of your NAT or firewall,
or an address that

770
00:35:34,425 --> 00:35:36,310
could be hosted in
a data center.

771
00:35:36,310 --> 00:35:40,410
And it does interactive checks
to figure out what is the best

772
00:35:40,410 --> 00:35:44,340
path between the two peers
to establish data.

773
00:35:44,340 --> 00:35:48,180
In our experience with Google
Talk, we find that in about

774
00:35:48,180 --> 00:35:51,290
90% of the cases, we can
actually establish a peer to

775
00:35:51,290 --> 00:35:53,900
peer link, even if both
sides are behind NAT.

776
00:35:53,900 --> 00:35:58,120
The rules of NAT are such that
if we know the address of the

777
00:35:58,120 --> 00:36:00,380
other person's NAT, we can still
get that peer to peer

778
00:36:00,380 --> 00:36:03,025
link going between two
peers using UDP.

779
00:36:03,025 --> 00:36:05,590

780
00:36:05,590 --> 00:36:06,840
AUDIENCE: Thanks.

781
00:36:06,840 --> 00:36:09,560

782
00:36:09,560 --> 00:36:10,020
AUDIENCE: Hi.

783
00:36:10,020 --> 00:36:11,420
Can you talk about
codec support?

784
00:36:11,420 --> 00:36:13,820
Because I know you guys have
acquired GIPS, and with that

785
00:36:13,820 --> 00:36:14,830
came iLBC and iSAC.

786
00:36:14,830 --> 00:36:17,460
But are you going to do
something like Opus support,

787
00:36:17,460 --> 00:36:19,020
or something like that?

788
00:36:19,020 --> 00:36:22,540
JUSTIN UBERTI: So this is all
a big topic for the IETF.

789
00:36:22,540 --> 00:36:25,770
But what we are planning
support, assuming we can work

790
00:36:25,770 --> 00:36:30,790
out all the licensing details,
VP8 will be our open, royalty

791
00:36:30,790 --> 00:36:32,330
free video codec.

792
00:36:32,330 --> 00:36:35,080
And then, as far as all your
codecs are concerned, we'll

793
00:36:35,080 --> 00:36:38,900
support G.711 for legacy
interoperability.

794
00:36:38,900 --> 00:36:40,840
We'll support iSAC.

795
00:36:40,840 --> 00:36:45,000
And we hope to support Opus,
assuming that Microsoft can

796
00:36:45,000 --> 00:36:47,210
help us out in the
licensing front.

797
00:36:47,210 --> 00:36:50,450
AUDIENCE: And can you talk about
iLBC voice quality on an

798
00:36:50,450 --> 00:36:51,930
Android platform?

799
00:36:51,930 --> 00:36:54,090
Have you guys had good
luck with it?

800
00:36:54,090 --> 00:36:56,150
I mean, are you seeing good
performance relative to a

801
00:36:56,150 --> 00:36:57,860
general cell phone call?

802
00:36:57,860 --> 00:36:59,700
JUSTIN UBERTI: We have the
person who wrote iLBC here

803
00:36:59,700 --> 00:37:00,975
sitting in the audience.

804
00:37:00,975 --> 00:37:02,250
AUDIENCE: That guy,
right there?

805
00:37:02,250 --> 00:37:02,330
JUSTIN UBERTI: Yeah, that guy.

806
00:37:02,330 --> 00:37:03,700
AUDIENCE: OK, I'll
talk to him.

807
00:37:03,700 --> 00:37:06,680
Thank you.

808
00:37:06,680 --> 00:37:08,480
AUDIENCE: Hi.

809
00:37:08,480 --> 00:37:12,540
Simple question, I saw on the
first demo that you showed how

810
00:37:12,540 --> 00:37:15,110
to use video.

811
00:37:15,110 --> 00:37:18,440
Well, you didn't show about
audio, but I guess audio is

812
00:37:18,440 --> 00:37:20,900
also included.

813
00:37:20,900 --> 00:37:23,490
Only on one to one conversation,
is there a way

814
00:37:23,490 --> 00:37:25,110
to make it broadcast?

815
00:37:25,110 --> 00:37:28,920
For example, this show can be
seen on the web page by

816
00:37:28,920 --> 00:37:31,350
multiple users?

817
00:37:31,350 --> 00:37:35,230
JUSTIN UBERTI: Yeah, so a
PeerConnection creates a

818
00:37:35,230 --> 00:37:37,800
connection between yourself
and a remote peer.

819
00:37:37,800 --> 00:37:41,090
And if you want to have a
multi-way conversation,

820
00:37:41,090 --> 00:37:43,270
there's a couple ways
you can do this.

821
00:37:43,270 --> 00:37:45,690
The first thing is you could
have multiple PeerConnections

822
00:37:45,690 --> 00:37:49,140
and establish a full mesh,
like I show here.

823
00:37:49,140 --> 00:37:52,020
If you have four participants,
you establish three

824
00:37:52,020 --> 00:37:56,080
PeerConnections, one of each
remote participant.

825
00:37:56,080 --> 00:37:57,810
This doesn't scale
all the way up.

826
00:37:57,810 --> 00:37:59,310
So one of the other things that
you can do as you get to

827
00:37:59,310 --> 00:38:02,210
be in a large conference, is
actually have a central server

828
00:38:02,210 --> 00:38:04,970
and create like a star topology,
where the other

829
00:38:04,970 --> 00:38:09,180
side, instead of being a
browser, is actually a server.

830
00:38:09,180 --> 00:38:12,130
And then using the WebRTC tools,
you can create a server

831
00:38:12,130 --> 00:38:15,110
that could do multi-party.

832
00:38:15,110 --> 00:38:19,970
AUDIENCE: OK, I think maybe
I asked you wrongly.

833
00:38:19,970 --> 00:38:23,170
I'm only interested one party
who is transmitting.

834
00:38:23,170 --> 00:38:26,950
The other ones don't need
to talk, only to listen.

835
00:38:26,950 --> 00:38:30,150
So it's like UDP
in that sense.

836
00:38:30,150 --> 00:38:30,870
JUSTIN UBERTI: Right, right.

837
00:38:30,870 --> 00:38:31,520
Sorry.

838
00:38:31,520 --> 00:38:34,550
In that case, the other side
wouldn't even have to call

839
00:38:34,550 --> 00:38:35,490
getUserMedia.

840
00:38:35,490 --> 00:38:39,050
So the side who calls
getUserMedia can specify

841
00:38:39,050 --> 00:38:42,710
whether it wants video
and/or audio.

842
00:38:42,710 --> 00:38:44,080
But you won't need to call
getUserMedia at all.

843
00:38:44,080 --> 00:38:47,480
So if you want to receive only,
you just would not call

844
00:38:47,480 --> 00:38:51,100
getUserMedia, and you wouldn't
call AddStream on that side.

845
00:38:51,100 --> 00:38:53,718
And then you would just play.

846
00:38:53,718 --> 00:38:54,570
AUDIENCE: I see.

847
00:38:54,570 --> 00:38:55,400
OK, thank you.

848
00:38:55,400 --> 00:38:56,650
JUSTIN UBERTI: Sure.

849
00:38:56,650 --> 00:38:58,480

850
00:38:58,480 --> 00:39:00,650
AUDIENCE: So if you want to
stream to the server and save

851
00:39:00,650 --> 00:39:04,762
the recorded video, are there
components or libraries that

852
00:39:04,762 --> 00:39:06,310
are available?

853
00:39:06,310 --> 00:39:10,060
JUSTIN UBERTI: So I mean, if
you're familiar with media

854
00:39:10,060 --> 00:39:13,110
processing, you can build these
kind of servers using

855
00:39:13,110 --> 00:39:15,400
the WebRTC components.

856
00:39:15,400 --> 00:39:20,090
There is something in the WebRTC
spec for an API called

857
00:39:20,090 --> 00:39:21,570
Media Recorder.

858
00:39:21,570 --> 00:39:23,400
It's missing a lot of
detail right now.

859
00:39:23,400 --> 00:39:24,730
So it's not being implemented.

860
00:39:24,730 --> 00:39:27,590
But we expect, at some point in
time, there will be an easy

861
00:39:27,590 --> 00:39:28,690
way to do media recording.

862
00:39:28,690 --> 00:39:31,570
For right now, the easiest way
is to build a server, make a

863
00:39:31,570 --> 00:39:32,620
PeerConnection to it.

864
00:39:32,620 --> 00:39:35,010
And then you can then save
it out to a file there.

865
00:39:35,010 --> 00:39:37,180
AUDIENCE: So the component would
be the C++ libraries

866
00:39:37,180 --> 00:39:38,620
that you would bind
into your server?

867
00:39:38,620 --> 00:39:39,870
JUSTIN UBERTI: Yes.

868
00:39:39,870 --> 00:39:43,190

869
00:39:43,190 --> 00:39:46,130
AUDIENCE: I had a question about
whether Screen Sharing

870
00:39:46,130 --> 00:39:50,070
is still in consideration
as a video source?

871
00:39:50,070 --> 00:39:51,320
JUSTIN UBERTI: It
absolutely is.

872
00:39:51,320 --> 00:39:54,590

873
00:39:54,590 --> 00:39:57,560
The question is whether Screen
Sharing will be supported as a

874
00:39:57,560 --> 00:39:58,690
video source.

875
00:39:58,690 --> 00:40:01,340
And it's sort of one of these
things where we definitely

876
00:40:01,340 --> 00:40:03,760
want to support it, we have
the technology to do it.

877
00:40:03,760 --> 00:40:06,670
But in terms of making sure we
get something out there, v1

878
00:40:06,670 --> 00:40:08,586
will be just video only.

879
00:40:08,586 --> 00:40:11,310
AUDIENCE: [INAUDIBLE].

880
00:40:11,310 --> 00:40:13,060
JUSTIN UBERTI: You could also
do it with camera drivers.

881
00:40:13,060 --> 00:40:14,730
Although, the issue with camera
drivers is that their

882
00:40:14,730 --> 00:40:17,825
resolution will be artificially
limited.

883
00:40:17,825 --> 00:40:19,460
AUDIENCE: Do you have
plans to integrate

884
00:40:19,460 --> 00:40:22,190
with Server-Sent Events?

885
00:40:22,190 --> 00:40:23,440
JUSTIN UBERTI: Server-Sent
Events.

886
00:40:23,440 --> 00:40:25,348

887
00:40:25,348 --> 00:40:29,620
Are you specific about what
you have in mind there?

888
00:40:29,620 --> 00:40:33,890
AUDIENCE: Well, to get the
session exchange pushed back

889
00:40:33,890 --> 00:40:35,130
the answer.

890
00:40:35,130 --> 00:40:36,640
JUSTIN UBERTI: I think I'll have
to get back you on that.

891
00:40:36,640 --> 00:40:37,860
I'm not sure I'm familiar
enough with

892
00:40:37,860 --> 00:40:39,800
the Server-Sent Events.

893
00:40:39,800 --> 00:40:42,850
AUDIENCE: They're part of the
[INAUDIBLE] working group

894
00:40:42,850 --> 00:40:43,915
specifications.

895
00:40:43,915 --> 00:40:45,165
JUSTIN UBERTI: We can
talk afterwards.

896
00:40:45,165 --> 00:40:47,560

897
00:40:47,560 --> 00:40:48,170
AUDIENCE: Hi.

898
00:40:48,170 --> 00:40:51,970
There will be any SIP
integration in the future?

899
00:40:51,970 --> 00:40:55,340
Any way to make a phone
call using these API?

900
00:40:55,340 --> 00:40:56,860
JUSTIN UBERTI: Yeah, so we
actually have some demos--

901
00:40:56,860 --> 00:40:57,860
I didn't show them today--

902
00:40:57,860 --> 00:41:00,810
where you can actually make
a phone call to the PSTN.

903
00:41:00,810 --> 00:41:04,860
And there's a couple
ways you can do it.

904
00:41:04,860 --> 00:41:07,100
You can send JSON to your web
server, and have the web

905
00:41:07,100 --> 00:41:09,540
server then gateway
that to SIP.

906
00:41:09,540 --> 00:41:12,720
Or there's a product
called sipML5--

907
00:41:12,720 --> 00:41:14,010
sipml5.org--

908
00:41:14,010 --> 00:41:15,910
where they're actually
implementing a SIP stack

909
00:41:15,910 --> 00:41:17,760
within the browser itself.

910
00:41:17,760 --> 00:41:21,460
So it converts the session
descriptions to SIP messages

911
00:41:21,460 --> 00:41:23,140
right inside the web
application.

912
00:41:23,140 --> 00:41:27,750
So you can definitely do SIP
calls using this technology.

913
00:41:27,750 --> 00:41:28,030
AUDIENCE: Great.

914
00:41:28,030 --> 00:41:32,250
And there will be an SDK for
Android, or something?

915
00:41:32,250 --> 00:41:34,770
JUSTIN UBERTI: Yeah, we
have existing SDK.

916
00:41:34,770 --> 00:41:39,460
If you go to WebRTC.org, you
can download the code for

917
00:41:39,460 --> 00:41:40,685
running this on Android.

918
00:41:40,685 --> 00:41:41,920
AUDIENCE: Thank you very much.

919
00:41:41,920 --> 00:41:43,170
JUSTIN UBERTI: Sure.

920
00:41:43,170 --> 00:41:46,040

921
00:41:46,040 --> 00:41:46,380
OK.

922
00:41:46,380 --> 00:41:47,920
Thank you all for coming.

923
00:41:47,920 --> 00:41:53,513
[APPLAUSE]

