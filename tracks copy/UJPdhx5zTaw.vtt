WEBVTT

1
00:00:00.000 --> 00:00:01.280

2
00:00:01.280 --> 00:00:02.420
Hello.

3
00:00:02.420 --> 00:00:04.210
Welcome to Breaking the
JavaScript Speed

4
00:00:04.210 --> 00:00:05.220
Barrier with V8.

5
00:00:05.220 --> 00:00:07.190
My name is Daniel Clifford.

6
00:00:07.190 --> 00:00:10.240
I'm the tech lead and manager
of the V8 team.

7
00:00:10.240 --> 00:00:12.410
If you'd like to follow along in
the slides, there's a link

8
00:00:12.410 --> 00:00:14.230
here on the first slide.

9
00:00:14.230 --> 00:00:18.060
It might help for you in the
back rows to read the smaller

10
00:00:18.060 --> 00:00:20.025
fonts in some of the
code slides later.

11
00:00:20.025 --> 00:00:23.720

12
00:00:23.720 --> 00:00:26.300
I'd like to talk to you today
about optimizing the

13
00:00:26.300 --> 00:00:28.020
performance of your
web application.

14
00:00:28.020 --> 00:00:30.130
Now this could mean a lot of
different things to a lot of

15
00:00:30.130 --> 00:00:31.090
different people.

16
00:00:31.090 --> 00:00:34.030
This could mean optimizing your
WebGL code to get more

17
00:00:34.030 --> 00:00:35.270
frames per second in the game.

18
00:00:35.270 --> 00:00:39.040
This could mean reducing the
number of network round trips

19
00:00:39.040 --> 00:00:40.910
in a client server
application.

20
00:00:40.910 --> 00:00:46.500
But what I'd like to talk to
you about today is Raw

21
00:00:46.500 --> 00:00:50.290
JavaScript Execution Performance
with V8, the

22
00:00:50.290 --> 00:00:53.110
JavaScript engine inside
of Chrome.

23
00:00:53.110 --> 00:00:56.150
The V8 project has recently
moved to the development

24
00:00:56.150 --> 00:00:58.860
center, the Google Development
Center in Munich, Germany.

25
00:00:58.860 --> 00:01:05.459
And as you may know, Germany is
the home of the Autobahn.

26
00:01:05.459 --> 00:01:08.520
And what you may not know is the
Autobahn is not actually a

27
00:01:08.520 --> 00:01:12.690
single stretch of road from
Hamburg to Munich that runs

28
00:01:12.690 --> 00:01:14.200
straight through the middle
of the country.

29
00:01:14.200 --> 00:01:15.950
But rather it's a network
of roads.

30
00:01:15.950 --> 00:01:19.030
And these days, most
of the Autobahn

31
00:01:19.030 --> 00:01:20.420
actually has a speed limit.

32
00:01:20.420 --> 00:01:23.590
But there are still a few
stretches of the road that

33
00:01:23.590 --> 00:01:25.880
don't have any speed
limit whatsoever.

34
00:01:25.880 --> 00:01:29.990
And you can go as fast as you
want, as fast as you can.

35
00:01:29.990 --> 00:01:34.280
And so, as a resident of Munich
and a resident of

36
00:01:34.280 --> 00:01:36.990
Germany, I feel especially
qualified to speak about

37
00:01:36.990 --> 00:01:39.000
moving at speeds that would get
you ticketed here in the

38
00:01:39.000 --> 00:01:40.250
United States.

39
00:01:40.250 --> 00:01:42.880

40
00:01:42.880 --> 00:01:44.770
You might ask the question, who
cares about performance?

41
00:01:44.770 --> 00:01:46.180
JavaScript performance
is fast enough.

42
00:01:46.180 --> 00:01:48.350
This is something that only game
developers need to worry

43
00:01:48.350 --> 00:01:50.490
about, or the developers
of highly interactive

44
00:01:50.490 --> 00:01:52.240
applications.

45
00:01:52.240 --> 00:01:55.450
But I'm here to tell you that
you should care about

46
00:01:55.450 --> 00:01:55.900
performance.

47
00:01:55.900 --> 00:01:58.690
Everybody who develops a web
application should care about

48
00:01:58.690 --> 00:01:59.690
performance.

49
00:01:59.690 --> 00:02:01.390
And the reason is, is that

50
00:02:01.390 --> 00:02:03.140
JavaScript performance matters.

51
00:02:03.140 --> 00:02:06.080
It still matters.

52
00:02:06.080 --> 00:02:08.210
It's not just about making
your current

53
00:02:08.210 --> 00:02:09.460
application run faster.

54
00:02:09.460 --> 00:02:11.760

55
00:02:11.760 --> 00:02:14.270
It's about enabling things that
you have never been able

56
00:02:14.270 --> 00:02:14.950
to do in the past.

57
00:02:14.950 --> 00:02:18.010
Every cycle that you win back
when you do performance

58
00:02:18.010 --> 00:02:21.560
optimization, you can invest
in something new that you

59
00:02:21.560 --> 00:02:23.430
haven't been able
to do before.

60
00:02:23.430 --> 00:02:25.280
An interesting comment about
these pictures, they were

61
00:02:25.280 --> 00:02:27.890
taken on the same street,
only a few feet away.

62
00:02:27.890 --> 00:02:30.490
I think it's interesting that
in the same place, given a

63
00:02:30.490 --> 00:02:32.290
slightly different perspective,
you can have a

64
00:02:32.290 --> 00:02:35.550
completely different
view of the world.

65
00:02:35.550 --> 00:02:36.800
So let's see.

66
00:02:36.800 --> 00:02:41.450
Let's talk about breaking
the speed limit today.

67
00:02:41.450 --> 00:02:47.570
I'd like to use a checklist as
the basis of how you optimize

68
00:02:47.570 --> 00:02:49.080
your web application.

69
00:02:49.080 --> 00:02:51.950
It's a relatively
straightforward model.

70
00:02:51.950 --> 00:02:54.390
But it's very powerful.

71
00:02:54.390 --> 00:02:57.880
And the first step of the
checklist is to make sure you

72
00:02:57.880 --> 00:03:00.320
are prepared before you
have a problem.

73
00:03:00.320 --> 00:03:02.620
This is the piece that is
the most expensive.

74
00:03:02.620 --> 00:03:04.180
This is the one that takes
the most amount of time.

75
00:03:04.180 --> 00:03:05.870
And I'll be spending the
most amount of time

76
00:03:05.870 --> 00:03:08.160
talking about it today.

77
00:03:08.160 --> 00:03:11.230
But this is the one that you
have to do to make the second

78
00:03:11.230 --> 00:03:13.770
two steps possible at all.

79
00:03:13.770 --> 00:03:16.540
The second step is to identify
and understand the crux of

80
00:03:16.540 --> 00:03:18.050
your problem.

81
00:03:18.050 --> 00:03:22.180
And if you know how
a system works.

82
00:03:22.180 --> 00:03:24.550
If you prepare before you go
into the second step, it makes

83
00:03:24.550 --> 00:03:27.650
it much easier to find
your problem.

84
00:03:27.650 --> 00:03:30.830
The third step, you
fix what matters.

85
00:03:30.830 --> 00:03:33.300
And hopefully this is the step
that's actually really easy

86
00:03:33.300 --> 00:03:36.920
after you've done
the first two.

87
00:03:36.920 --> 00:03:40.050
Now, this is a relatively
simple model.

88
00:03:40.050 --> 00:03:41.700
But, like I said, it's
very powerful.

89
00:03:41.700 --> 00:03:45.230
And you can even apply it to
real world situations.

90
00:03:45.230 --> 00:03:47.460
So I'd like to tell you a story

91
00:03:47.460 --> 00:03:48.800
about using the checklist.

92
00:03:48.800 --> 00:03:52.450
And I like to do recreational
mountain climbing.

93
00:03:52.450 --> 00:03:53.340
I'm not very good at it.

94
00:03:53.340 --> 00:03:55.190
But I have a friend
who is very good

95
00:03:55.190 --> 00:03:56.900
at it, Michael Stanton.

96
00:03:56.900 --> 00:03:59.130
And he's taught me
everything I know

97
00:03:59.130 --> 00:04:00.700
about mountain climbing.

98
00:04:00.700 --> 00:04:03.420
And I trust him on
the mountain.

99
00:04:03.420 --> 00:04:04.700
I trust him with my life.

100
00:04:04.700 --> 00:04:07.150
And that's how we found
ourselves in the summer of

101
00:04:07.150 --> 00:04:10.040
2010 up here.

102
00:04:10.040 --> 00:04:11.650
And it was a beautiful day.

103
00:04:11.650 --> 00:04:13.030
We'd been on the mountain
all day.

104
00:04:13.030 --> 00:04:14.210
We hadn't seen another soul.

105
00:04:14.210 --> 00:04:15.960
We had the whole mountain
to ourselves.

106
00:04:15.960 --> 00:04:18.820
And we were two rope lengths
from the top, from the summit.

107
00:04:18.820 --> 00:04:20.589
We were almost there.

108
00:04:20.589 --> 00:04:21.970
And I was belaying Michael.

109
00:04:21.970 --> 00:04:23.840
I was making sure that if
he were to fall that

110
00:04:23.840 --> 00:04:24.520
I would catch him.

111
00:04:24.520 --> 00:04:26.280
And he was leading ahead.

112
00:04:26.280 --> 00:04:29.700
And he climbed ahead of me
around a corner, out of sight.

113
00:04:29.700 --> 00:04:31.620
And I heard him struggling with
a particularly tricky

114
00:04:31.620 --> 00:04:32.300
climbing problem.

115
00:04:32.300 --> 00:04:35.290
Then I heard two sounds that I
will never forget in my life.

116
00:04:35.290 --> 00:04:39.200
And the first one was the
percussive sound of a rock

117
00:04:39.200 --> 00:04:40.160
coming loose.

118
00:04:40.160 --> 00:04:43.707
And the second sound was the
sickening thud of that rock

119
00:04:43.707 --> 00:04:46.110
hitting Michael.

120
00:04:46.110 --> 00:04:48.070
He fell.

121
00:04:48.070 --> 00:04:49.680
I called his name.

122
00:04:49.680 --> 00:04:52.640
But all I heard was silence.

123
00:04:52.640 --> 00:04:55.895
I realized in that moment that
I had a performance problem.

124
00:04:55.895 --> 00:04:58.740

125
00:04:58.740 --> 00:05:02.100
And the checklist that I just
presented to you would be the

126
00:05:02.100 --> 00:05:05.650
key for me to get out
of that situation.

127
00:05:05.650 --> 00:05:09.630
I had to be prepared before I
ever got on that mountain.

128
00:05:09.630 --> 00:05:13.320
I had to make sure to identify
the problem that I had in that

129
00:05:13.320 --> 00:05:15.090
very moment, the key
problem, so that I

130
00:05:15.090 --> 00:05:16.490
could fix it quickly.

131
00:05:16.490 --> 00:05:19.710
Somebody's life could
depend on it.

132
00:05:19.710 --> 00:05:24.030
Now, I hope you never are in a
situation like that, that your

133
00:05:24.030 --> 00:05:26.690
life depends on applying
the checklist.

134
00:05:26.690 --> 00:05:29.960
So why don't we go to an
example, which talks about a

135
00:05:29.960 --> 00:05:32.430
less life threatening
performance problem.

136
00:05:32.430 --> 00:05:34.940
Let's talk about JavaScript.

137
00:05:34.940 --> 00:05:38.290
So I have put together a sample
problem that I'd like

138
00:05:38.290 --> 00:05:40.900
to talk about throughout the
course of this talk.

139
00:05:40.900 --> 00:05:44.690
And it is a toy problem that
I've come up with.

140
00:05:44.690 --> 00:05:46.030
But I think it's representative
of some of the

141
00:05:46.030 --> 00:05:46.710
things that--

142
00:05:46.710 --> 00:05:48.260
some of the performance problems
that you might face

143
00:05:48.260 --> 00:05:49.590
in your own code.

144
00:05:49.590 --> 00:05:54.980
And the problem is to compute
the 25,000th prime.

145
00:05:54.980 --> 00:05:57.880
Pretty simple algorithm here,
you start at one.

146
00:05:57.880 --> 00:05:59.120
You count up.

147
00:05:59.120 --> 00:06:02.180
And you take each candidate
number.

148
00:06:02.180 --> 00:06:04.260
And you look in a list of primes
that you're maintaining

149
00:06:04.260 --> 00:06:07.720
and see if any of those primes
can be divided into that

150
00:06:07.720 --> 00:06:08.590
candidate number.

151
00:06:08.590 --> 00:06:10.690
And if it can, then
the candidate

152
00:06:10.690 --> 00:06:12.030
number is not a prime.

153
00:06:12.030 --> 00:06:14.940
If none of the prime numbers go
into that candidate number,

154
00:06:14.940 --> 00:06:19.150
then we have a new prime
and we add it to list.

155
00:06:19.150 --> 00:06:25.330
And I wrote some code in
C++ and in JavaScript.

156
00:06:25.330 --> 00:06:27.730
Don't sweat the details
of this code.

157
00:06:27.730 --> 00:06:29.390
I just wanted to show you
that it's about the

158
00:06:29.390 --> 00:06:30.170
same amount of code.

159
00:06:30.170 --> 00:06:33.600
And I tried to do a pretty good
job of porting the code

160
00:06:33.600 --> 00:06:35.410
from JavaScript to C++.

161
00:06:35.410 --> 00:06:36.660
So it does the same thing.

162
00:06:36.660 --> 00:06:39.520

163
00:06:39.520 --> 00:06:42.280
And then what I did is I
actually ran the code.

164
00:06:42.280 --> 00:06:47.490
I compiled the C++ code
with GCC and ran it.

165
00:06:47.490 --> 00:06:51.580
And you can see it took about
three seconds to compute the

166
00:06:51.580 --> 00:06:53.840
25,000th prime.

167
00:06:53.840 --> 00:06:56.030
Then I took the JavaScript
code.

168
00:06:56.030 --> 00:06:57.090
And I didn't run
it in browser.

169
00:06:57.090 --> 00:06:58.910
What I did was I took the
debugging shell that's

170
00:06:58.910 --> 00:07:01.530
available as part of the V8
open source code project.

171
00:07:01.530 --> 00:07:05.250
And I compiled that and ran
the JavaScript with the

172
00:07:05.250 --> 00:07:06.240
debugging shell.

173
00:07:06.240 --> 00:07:08.030
The debugging shell makes
it possible for you to

174
00:07:08.030 --> 00:07:10.350
concentrate on JavaScript
specific problems.

175
00:07:10.350 --> 00:07:13.620
So for this presentation, I'll
refer to the debugging shell

176
00:07:13.620 --> 00:07:14.950
in most of my examples.

177
00:07:14.950 --> 00:07:19.700
You'll see that when I ran the
prime code in JavaScript, it

178
00:07:19.700 --> 00:07:24.060
took 15 seconds.

179
00:07:24.060 --> 00:07:28.290
So JavaScript's about five
times slower than C++.

180
00:07:28.290 --> 00:07:29.540
That's not so bad, right?

181
00:07:29.540 --> 00:07:31.760

182
00:07:31.760 --> 00:07:34.800
Of course it is, yeah.

183
00:07:34.800 --> 00:07:37.880
So I just made a big mistake.

184
00:07:37.880 --> 00:07:39.490
I've told you about
this checklist.

185
00:07:39.490 --> 00:07:42.070
And I just completely
ignored it.

186
00:07:42.070 --> 00:07:43.910
I was not prepared.

187
00:07:43.910 --> 00:07:45.660
I don't have enough information
to make judgment

188
00:07:45.660 --> 00:07:49.120
about whether my code is bad or
good, whether that number

189
00:07:49.120 --> 00:07:51.290
is something I should
expect or not.

190
00:07:51.290 --> 00:07:53.910
I didn't even try
to analyze any

191
00:07:53.910 --> 00:07:55.810
potential performance problem.

192
00:07:55.810 --> 00:08:01.100
And I didn't even get anywhere
close to fixing any problem.

193
00:08:01.100 --> 00:08:05.180
I'd like to show you
how V8 has improved

194
00:08:05.180 --> 00:08:07.480
since Chrome came out.

195
00:08:07.480 --> 00:08:11.100
This is V8's score on the V8
benchmark, version seven.

196
00:08:11.100 --> 00:08:13.780
And you can see that it's
got a lot better

197
00:08:13.780 --> 00:08:16.120
since we launched Chrome.

198
00:08:16.120 --> 00:08:20.830
And we're now at the position
with V8 that we can actually

199
00:08:20.830 --> 00:08:25.690
make a comparison against the
performance of C and C++ code.

200
00:08:25.690 --> 00:08:30.620
You can expect to be in the
ballpark for certain code.

201
00:08:30.620 --> 00:08:33.330
So don't give up here.

202
00:08:33.330 --> 00:08:36.000
When you're in the same
situation, where you say,

203
00:08:36.000 --> 00:08:37.549
we're slower than C++.

204
00:08:37.549 --> 00:08:39.030
Or I'm slower where
I want to be.

205
00:08:39.030 --> 00:08:40.760
Don't just give up.

206
00:08:40.760 --> 00:08:43.370
Apply the checklist that
I presented to you.

207
00:08:43.370 --> 00:08:45.630
And see how far you can get.

208
00:08:45.630 --> 00:08:50.260
Demand that your application
is faster.

209
00:08:50.260 --> 00:08:53.680
So how much faster do you
think we can get the

210
00:08:53.680 --> 00:08:56.680
JavaScript code to run?

211
00:08:56.680 --> 00:08:58.130
Who here thinks we can do it--

212
00:08:58.130 --> 00:09:00.921
we can get it three and
a half times faster?

213
00:09:00.921 --> 00:09:03.650
All right, we've got
maybe 5, 10 people.

214
00:09:03.650 --> 00:09:04.810
35 times?

215
00:09:04.810 --> 00:09:06.080
Takers?

216
00:09:06.080 --> 00:09:08.430
OK, also a couple of people,
I know you know

217
00:09:08.430 --> 00:09:09.520
how this game works.

218
00:09:09.520 --> 00:09:12.030
350 times?

219
00:09:12.030 --> 00:09:17.305
OK, one person, the V8 PMs.

220
00:09:17.305 --> 00:09:19.650
[LAUGHTER]

221
00:09:19.650 --> 00:09:22.090
3,500?

222
00:09:22.090 --> 00:09:25.140
All right, we've got to get at
least one brave taker here.

223
00:09:25.140 --> 00:09:29.910
So I think the most votes
were for 35 times.

224
00:09:29.910 --> 00:09:34.770
Let's apply the checklist and
see how far we can get.

225
00:09:34.770 --> 00:09:38.450
Now I told you the first step
was to be prepared.

226
00:09:38.450 --> 00:09:40.270
And this means we're going to
dive into some technical

227
00:09:40.270 --> 00:09:44.450
details of V8, so you can
understand how it works.

228
00:09:44.450 --> 00:09:46.730
So fasten your seat belts.

229
00:09:46.730 --> 00:09:51.410
This is where things get
a little bit racy.

230
00:09:51.410 --> 00:09:53.460
So what does prepared
mean for V8?

231
00:09:53.460 --> 00:09:54.840
I mentioned this before.

232
00:09:54.840 --> 00:09:57.860
You need to understand
how V8 optimizes

233
00:09:57.860 --> 00:09:59.000
your JavaScript code.

234
00:09:59.000 --> 00:10:02.330
You need to understand how V8
actually works so that you can

235
00:10:02.330 --> 00:10:05.070
help it optimize your code.

236
00:10:05.070 --> 00:10:08.770
Because once you understand how
V8 works, then when you

237
00:10:08.770 --> 00:10:10.780
actually write your JavaScript
code, you can keep those

238
00:10:10.780 --> 00:10:12.400
things in mind and make sure
that you don't make some of

239
00:10:12.400 --> 00:10:16.850
the mistakes that
will fool V8.

240
00:10:16.850 --> 00:10:19.020
Make sure you learn the tools
that are available to you.

241
00:10:19.020 --> 00:10:21.770
There's some great tools in
Chrome, the dev tools.

242
00:10:21.770 --> 00:10:25.520
And V8 has some built-in tools
in the debugging shell that

243
00:10:25.520 --> 00:10:27.350
can really help you understand
what's going on in your

244
00:10:27.350 --> 00:10:29.050
JavaScript and help you
make it better.

245
00:10:29.050 --> 00:10:31.770

246
00:10:31.770 --> 00:10:32.020
All right.

247
00:10:32.020 --> 00:10:33.620
So the first thing I'd
like to talk to you

248
00:10:33.620 --> 00:10:36.720
about is hidden classes.

249
00:10:36.720 --> 00:10:40.070
So JavaScript doesn't
have explicit types.

250
00:10:40.070 --> 00:10:43.260
And this presents a bit of
a challenge to a language

251
00:10:43.260 --> 00:10:46.930
implementer, because type
information is very valuable

252
00:10:46.930 --> 00:10:50.750
in specializing generated code
to be very efficient.

253
00:10:50.750 --> 00:10:52.870
And if you don't have that type
information, it makes it

254
00:10:52.870 --> 00:10:54.520
much more difficult.

255
00:10:54.520 --> 00:10:57.180
And it's hard to gather this
information efficiently and

256
00:10:57.180 --> 00:10:59.290
quickly when you're compiling
JavaScript code because

257
00:10:59.290 --> 00:11:02.230
compilation is part of
the execution time of

258
00:11:02.230 --> 00:11:03.140
a JavaScript program.

259
00:11:03.140 --> 00:11:06.870
Every cycle that you spend
compiling a JavaScript script

260
00:11:06.870 --> 00:11:10.050
before you execute it is a cycle
longer than it takes to

261
00:11:10.050 --> 00:11:11.830
actually get to doing
the work.

262
00:11:11.830 --> 00:11:15.730
So we have to find a way
to get executing

263
00:11:15.730 --> 00:11:17.000
code as fast as possible.

264
00:11:17.000 --> 00:11:20.950
And it makes it difficult to do
expensive reasoning about

265
00:11:20.950 --> 00:11:23.470
types at compilation time.

266
00:11:23.470 --> 00:11:26.440
And that makes it extremely
difficult to get it close to

267
00:11:26.440 --> 00:11:29.700
the performance of C++.

268
00:11:29.700 --> 00:11:34.170
However, there are
some tricks.

269
00:11:34.170 --> 00:11:39.250
Hidden classes help make V8
run JavaScript faster.

270
00:11:39.250 --> 00:11:44.550
V8 internally creates hidden
classes for objects at run

271
00:11:44.550 --> 00:11:47.290
time, not at compile time.

272
00:11:47.290 --> 00:11:50.510
And that's how we get around
the problem of compiling

273
00:11:50.510 --> 00:11:52.820
upfront, getting the information
upfront, because

274
00:11:52.820 --> 00:11:56.480
we gather the hidden class
information as we go.

275
00:11:56.480 --> 00:11:58.150
And here's a key insight.

276
00:11:58.150 --> 00:12:00.000
And this is one that we'll
repeat throughout the

277
00:12:00.000 --> 00:12:00.600
presentation.

278
00:12:00.600 --> 00:12:03.530
Objects with the same hidden
class can use the same

279
00:12:03.530 --> 00:12:05.390
optimized generated code.

280
00:12:05.390 --> 00:12:08.710
And that means if you help teach
V8 through the way that

281
00:12:08.710 --> 00:12:11.920
you structure your code, which
object has the same hidden

282
00:12:11.920 --> 00:12:15.300
class, you can help it to
generate optimized code for

283
00:12:15.300 --> 00:12:17.490
those cases.

284
00:12:17.490 --> 00:12:18.940
I'd like to show you
how this works in

285
00:12:18.940 --> 00:12:21.180
a very simple example.

286
00:12:21.180 --> 00:12:23.650
So I've got a constructor
function here

287
00:12:23.650 --> 00:12:25.870
for an object point.

288
00:12:25.870 --> 00:12:28.700
And I'm going to instantiate
it twice.

289
00:12:28.700 --> 00:12:32.470
And let's see actually what
V8 does behind the scenes.

290
00:12:32.470 --> 00:12:37.020
So the first time the
constructor gets called, V8

291
00:12:37.020 --> 00:12:38.260
creates a new hidden class.

292
00:12:38.260 --> 00:12:40.910
So what you see here is-- on the
right hand side-- is you

293
00:12:40.910 --> 00:12:43.160
see the new point object.

294
00:12:43.160 --> 00:12:47.940
The first entry in the point
object is a hidden class to an

295
00:12:47.940 --> 00:12:50.420
empty point hidden class.

296
00:12:50.420 --> 00:12:54.750
And as we assign to the members,
in point, what V8

297
00:12:54.750 --> 00:12:57.750
does is actually realizes, ah,
you're changing the hidden

298
00:12:57.750 --> 00:13:00.020
class by adding a
member to it.

299
00:13:00.020 --> 00:13:03.610
And we create a new
hidden class.

300
00:13:03.610 --> 00:13:06.280
And the point object
gets assigned to

301
00:13:06.280 --> 00:13:07.510
this new hidden class.

302
00:13:07.510 --> 00:13:09.680
And if we had another member--

303
00:13:09.680 --> 00:13:10.920
in this case y--

304
00:13:10.920 --> 00:13:12.740
we get yet another
hidden class.

305
00:13:12.740 --> 00:13:15.190
And you see what happens here
is that not only does V8

306
00:13:15.190 --> 00:13:18.120
create new hidden classes as
new members are added.

307
00:13:18.120 --> 00:13:21.480
But it keeps track of what had
to happen to get from one

308
00:13:21.480 --> 00:13:23.500
hidden class to another one.

309
00:13:23.500 --> 00:13:26.290
So you see we went from empty
point object to a point object

310
00:13:26.290 --> 00:13:31.190
with an x, to a point object
with an x and a y.

311
00:13:31.190 --> 00:13:34.880
And that's important because the
second time that we call

312
00:13:34.880 --> 00:13:38.890
the point constructor, this
hidden class structure is

313
00:13:38.890 --> 00:13:40.460
already there.

314
00:13:40.460 --> 00:13:44.720
And as the code is executed to
add the members x and the

315
00:13:44.720 --> 00:13:49.160
members y, you'll see
that the object also

316
00:13:49.160 --> 00:13:50.650
gets new hidden classes.

317
00:13:50.650 --> 00:13:52.570
But it gets the same hidden
classes that we created the

318
00:13:52.570 --> 00:13:54.050
first time through.

319
00:13:54.050 --> 00:13:59.290
So that at the end, we actually
have P1 and P2 having

320
00:13:59.290 --> 00:14:01.050
the same hidden class.

321
00:14:01.050 --> 00:14:06.670
The problem is, is that if we
add a member to P2 that we

322
00:14:06.670 --> 00:14:08.040
haven't added to P1--

323
00:14:08.040 --> 00:14:10.550
after the fact, outside
of the constructor--

324
00:14:10.550 --> 00:14:13.020
what happens is that we
create yet another

325
00:14:13.020 --> 00:14:14.810
hidden class for P2.

326
00:14:14.810 --> 00:14:17.660
And it is different from
the class for P1.

327
00:14:17.660 --> 00:14:20.780
So they are now-- we're not able
to use the same optimize

328
00:14:20.780 --> 00:14:23.050
code for both of
those objects.

329
00:14:23.050 --> 00:14:27.880
So be aware that by doing
something like this and

330
00:14:27.880 --> 00:14:29.780
creating hidden classes, you're
defeating some of the

331
00:14:29.780 --> 00:14:34.480
optimizations that V8 can do.

332
00:14:34.480 --> 00:14:37.990
I'd like to talk about speed
traps to avoid in this

333
00:14:37.990 --> 00:14:39.030
presentation.

334
00:14:39.030 --> 00:14:41.690
For the most part, all of the
advice I'm going to give you

335
00:14:41.690 --> 00:14:44.050
today is something
that is eternal.

336
00:14:44.050 --> 00:14:47.850
You can assume that the tips
that I give you today you can

337
00:14:47.850 --> 00:14:50.530
use forever, except for a couple
of cases where I'll

338
00:14:50.530 --> 00:14:52.280
say, this is something that's
temporary, something that

339
00:14:52.280 --> 00:14:54.230
we're working on and we're
trying to make better.

340
00:14:54.230 --> 00:14:57.580
So let's get to the first speed
trap, which is make sure

341
00:14:57.580 --> 00:15:00.070
to initialize all members in
your constructor functions.

342
00:15:00.070 --> 00:15:02.470
This comes from the example I
just showed you, which is you

343
00:15:02.470 --> 00:15:06.100
need to teach V8 which hidden
class objects should have

344
00:15:06.100 --> 00:15:07.150
after they're constructed.

345
00:15:07.150 --> 00:15:09.730
And the way to do that is by
putting all of the member

346
00:15:09.730 --> 00:15:12.450
initialization in
the constructor.

347
00:15:12.450 --> 00:15:15.490
Always initialize object members
in the same order.

348
00:15:15.490 --> 00:15:18.310
This follows from that example
that I gave you.

349
00:15:18.310 --> 00:15:21.710
If you add members in different
orders, you create a

350
00:15:21.710 --> 00:15:23.720
different tree of
hidden classes.

351
00:15:23.720 --> 00:15:25.950
And at the end, you'll have
objects with two different

352
00:15:25.950 --> 00:15:27.840
hidden classes that can't use
the same optimized code.

353
00:15:27.840 --> 00:15:31.370

354
00:15:31.370 --> 00:15:36.290
Next thing I'd like to talk
about are numbers.

355
00:15:36.290 --> 00:15:39.870
So because we don't have a lot
of type information in

356
00:15:39.870 --> 00:15:42.560
JavaScript, we have
this dilemma.

357
00:15:42.560 --> 00:15:45.400
We want to be able to generate
code that can handle all

358
00:15:45.400 --> 00:15:49.700
possible different values, all
different possible types.

359
00:15:49.700 --> 00:15:52.560
But you want to be able
to have an efficient

360
00:15:52.560 --> 00:15:55.400
representation of numbers.

361
00:15:55.400 --> 00:15:56.470
And how do we do this?

362
00:15:56.470 --> 00:15:59.530
Well, we use a technique
called tagging.

363
00:15:59.530 --> 00:16:02.380
So inside of V8 we pass
around values of

364
00:16:02.380 --> 00:16:05.310
32-bit numbers and objects.

365
00:16:05.310 --> 00:16:07.800
But we want to be able to
use the same 32 bits

366
00:16:07.800 --> 00:16:09.240
to represent both.

367
00:16:09.240 --> 00:16:12.580
And that way we can have one
code path that can handle, in

368
00:16:12.580 --> 00:16:16.020
many cases, the objects
and integers.

369
00:16:16.020 --> 00:16:19.240
So what we do is we use
the bottom bit.

370
00:16:19.240 --> 00:16:22.110
And each of the values have
a special meaning.

371
00:16:22.110 --> 00:16:24.695
If the bit is set, it's
an object pointer.

372
00:16:24.695 --> 00:16:28.470
If it's clear, it's what we
call small integer or smi.

373
00:16:28.470 --> 00:16:32.120
And that's a 31-bit
signed integer.

374
00:16:32.120 --> 00:16:34.660
Now if you have a numeric value
that you're passing

375
00:16:34.660 --> 00:16:37.810
around, assigning to a member
that is bigger--

376
00:16:37.810 --> 00:16:41.620
it's a numeric value that's
bigger than 31 signed bits--

377
00:16:41.620 --> 00:16:45.420
then it doesn't fit in
one of these smis.

378
00:16:45.420 --> 00:16:47.400
And we have to create what's
called a box for it.

379
00:16:47.400 --> 00:16:49.160
We box the number.

380
00:16:49.160 --> 00:16:50.490
We turn it into a double.

381
00:16:50.490 --> 00:16:53.380
And we create a new object to
put that number inside of it.

382
00:16:53.380 --> 00:16:56.960
And what follows from that is
the next speed trap to avoid,

383
00:16:56.960 --> 00:17:02.340
which is make sure, whenever
possible, you use 31-bit

384
00:17:02.340 --> 00:17:06.510
signed numbers for performance
critical calculations.

385
00:17:06.510 --> 00:17:09.819
Because if you exceed 31 signed
bits, we will have to

386
00:17:09.819 --> 00:17:12.000
convert it to a double value.

387
00:17:12.000 --> 00:17:14.369
Now there's some optimizations
that we have that doesn't make

388
00:17:14.369 --> 00:17:15.390
it as bad as it seems.

389
00:17:15.390 --> 00:17:18.859
But there are cases where that
process causes an allocation.

390
00:17:18.859 --> 00:17:20.790
And that means that some
mathematical operations can

391
00:17:20.790 --> 00:17:22.040
cause allocation.

392
00:17:22.040 --> 00:17:25.250

393
00:17:25.250 --> 00:17:26.940
The next thing I'd like to
talk about is arrays.

394
00:17:26.940 --> 00:17:28.840
This brings some of the elements
together of the

395
00:17:28.840 --> 00:17:30.880
previous two sections.

396
00:17:30.880 --> 00:17:32.610
In JavaScript, you can have
very large arrays.

397
00:17:32.610 --> 00:17:34.440
And you can have arrays that
are sparse, that don't have

398
00:17:34.440 --> 00:17:36.230
every element inside of them.

399
00:17:36.230 --> 00:17:40.230
And so V8 actually has two
different methods to handle

400
00:17:40.230 --> 00:17:41.710
two different types of arrays.

401
00:17:41.710 --> 00:17:43.990
The first one is
fast elements.

402
00:17:43.990 --> 00:17:47.400
And fast elements, they have
a linear storage buffer.

403
00:17:47.400 --> 00:17:49.840
And V8 uses them if the
set of keys for the

404
00:17:49.840 --> 00:17:51.600
array is very compact.

405
00:17:51.600 --> 00:17:54.150

406
00:17:54.150 --> 00:17:56.830
If that's not the case-- so you
have a very sparse array--

407
00:17:56.830 --> 00:17:58.150
then it uses a different
format, which

408
00:17:58.150 --> 00:17:59.830
is dictionary elements.

409
00:17:59.830 --> 00:18:03.380
Fast elements, linear buffer,
very fast and

410
00:18:03.380 --> 00:18:05.550
efficient to access.

411
00:18:05.550 --> 00:18:07.930
Dictionary elements,
it's a hash table.

412
00:18:07.930 --> 00:18:11.410
Much more compact but
also more expensive

413
00:18:11.410 --> 00:18:12.660
at run time to access.

414
00:18:12.660 --> 00:18:15.670

415
00:18:15.670 --> 00:18:19.600
Kind of obvious here, if you
want to have your arrays be

416
00:18:19.600 --> 00:18:24.310
very fast, make sure that
V8 uses fast elements to

417
00:18:24.310 --> 00:18:24.870
represent them.

418
00:18:24.870 --> 00:18:28.090
And the way to do this is to
make sure that your keys start

419
00:18:28.090 --> 00:18:30.390
at zero and that they're
contiguous.

420
00:18:30.390 --> 00:18:33.620
So don't create an array
and start using

421
00:18:33.620 --> 00:18:36.280
index number 25,000.

422
00:18:36.280 --> 00:18:40.010
Start at zero and go up.

423
00:18:40.010 --> 00:18:43.990
Also, don't allocate really
large arrays that you're not

424
00:18:43.990 --> 00:18:45.160
going to use everything in.

425
00:18:45.160 --> 00:18:48.390
So if you allocate an array with
65,000 elements and you

426
00:18:48.390 --> 00:18:51.070
only use the first five, V8
thinks, well, that's a very

427
00:18:51.070 --> 00:18:55.050
sparse array, and will switch
into dictionary mode, which

428
00:18:55.050 --> 00:19:00.250
means the access of the elements
will be slower.

429
00:19:00.250 --> 00:19:02.970
Don't delete elements
inside of arrays.

430
00:19:02.970 --> 00:19:05.900
Same principle here, because
when you delete elements, it

431
00:19:05.900 --> 00:19:08.910
makes the key set sparse.

432
00:19:08.910 --> 00:19:11.780
And it can lead to V8 switching
the elements to

433
00:19:11.780 --> 00:19:14.620
dictionary mode.

434
00:19:14.620 --> 00:19:17.650
Don't load from uninitialized
or deleted elements.

435
00:19:17.650 --> 00:19:18.710
This is an important one.

436
00:19:18.710 --> 00:19:21.440
It's easy to get wrong.

437
00:19:21.440 --> 00:19:22.960
Here's an example.

438
00:19:22.960 --> 00:19:24.430
Your code will work.

439
00:19:24.430 --> 00:19:25.750
You won't notice.

440
00:19:25.750 --> 00:19:27.930
And it won't make a difference
in the output.

441
00:19:27.930 --> 00:19:30.350
However, it will make
things a lot slower.

442
00:19:30.350 --> 00:19:33.630
So here's an example of
doing exactly this.

443
00:19:33.630 --> 00:19:37.330
I have a loop here that
accesses an array.

444
00:19:37.330 --> 00:19:39.570
And it uses the or equals
operator, which means it takes

445
00:19:39.570 --> 00:19:42.380
the existing value in the array,
ors it to something and

446
00:19:42.380 --> 00:19:43.210
then writes it back.

447
00:19:43.210 --> 00:19:47.770
But the first time that you do
that, you're accessing an

448
00:19:47.770 --> 00:19:50.150
empty array.

449
00:19:50.150 --> 00:19:53.960
And when you do that, the
JavaScript spec says, that's

450
00:19:53.960 --> 00:19:55.480
an undefined value.

451
00:19:55.480 --> 00:19:56.270
But that's OK.

452
00:19:56.270 --> 00:19:57.410
It can be converted to zero.

453
00:19:57.410 --> 00:19:59.640
And it's exactly what
it does here.

454
00:19:59.640 --> 00:20:01.660
It converts that zero to do the
or equals and then stores

455
00:20:01.660 --> 00:20:01.940
it back in.

456
00:20:01.940 --> 00:20:04.990
But that process of conversion
means that this operation has

457
00:20:04.990 --> 00:20:05.740
to do more checking.

458
00:20:05.740 --> 00:20:07.300
And it's more expensive.

459
00:20:07.300 --> 00:20:10.030
And by simply initializing the
value before you use it--

460
00:20:10.030 --> 00:20:12.200
that's the second
example here--

461
00:20:12.200 --> 00:20:14.020
you can make your code,
in this case,

462
00:20:14.020 --> 00:20:15.270
about twice as fast.

463
00:20:15.270 --> 00:20:18.100

464
00:20:18.100 --> 00:20:20.200
So what about arrays
of doubles?

465
00:20:20.200 --> 00:20:22.350
Remember I talked about tagging,
that we have to wrap

466
00:20:22.350 --> 00:20:26.100
double numbers inside
of special objects.

467
00:20:26.100 --> 00:20:27.480
So if you have an array of them,
doesn't that make it

468
00:20:27.480 --> 00:20:29.880
expensive because each element
has to have this wrapper

469
00:20:29.880 --> 00:20:32.230
object to store the
double value.

470
00:20:32.230 --> 00:20:35.480
Well, there's a trick that we
can use there too as well.

471
00:20:35.480 --> 00:20:39.520
So we have a mechanism
called unboxing.

472
00:20:39.520 --> 00:20:44.450
When you unbox a double, you
take the 64-bit IEEE number

473
00:20:44.450 --> 00:20:46.200
inside of this double object.

474
00:20:46.200 --> 00:20:47.100
And you take it out.

475
00:20:47.100 --> 00:20:49.650
And you put it into
a linear buffer.

476
00:20:49.650 --> 00:20:54.740
So what we can do is track in
the hidden class of an array

477
00:20:54.740 --> 00:20:56.720
the types of elements that are
contained in the array.

478
00:20:56.720 --> 00:20:59.620
And if the array contains
only double

479
00:20:59.620 --> 00:21:02.075
values, it becomes unboxed.

480
00:21:02.075 --> 00:21:04.550
And what that means is that it
takes all of those numbers out

481
00:21:04.550 --> 00:21:07.800
of the heap objects, out of the
wrapper objects, and lays

482
00:21:07.800 --> 00:21:10.900
them out in a linear
buffer of doubles.

483
00:21:10.900 --> 00:21:12.900
But again, it's only if there
are double numbers

484
00:21:12.900 --> 00:21:15.720
inside of the array.

485
00:21:15.720 --> 00:21:18.290
This causes the hidden
class change.

486
00:21:18.290 --> 00:21:20.970
Generally, that's good because
if you convert the double

487
00:21:20.970 --> 00:21:22.470
numbers into a flat buffer--

488
00:21:22.470 --> 00:21:25.090
if you have array of doubles
and it's in a flat

489
00:21:25.090 --> 00:21:28.150
representation, it's very
efficient to access that.

490
00:21:28.150 --> 00:21:29.830
And when you store into it,
it doesn't require any

491
00:21:29.830 --> 00:21:30.950
allocation.

492
00:21:30.950 --> 00:21:35.280
But you must be aware that
converting between the array

493
00:21:35.280 --> 00:21:37.650
that's boxed and unboxed
has a cost.

494
00:21:37.650 --> 00:21:40.490
And it changes the
hidden class.

495
00:21:40.490 --> 00:21:44.170
And careless manipulation of
arrays can lead to a lot of

496
00:21:44.170 --> 00:21:46.500
extra work through this
boxing and unboxing.

497
00:21:46.500 --> 00:21:49.180
I'll give you an example
of that.

498
00:21:49.180 --> 00:21:52.250
Here's a pretty simple
snippet of code.

499
00:21:52.250 --> 00:21:53.220
I create a new array.

500
00:21:53.220 --> 00:21:55.860
And I sign a bunch
of values to the

501
00:21:55.860 --> 00:21:57.920
first couple of elements.

502
00:21:57.920 --> 00:22:00.730
Looks like there's not a whole
lot of work to do here.

503
00:22:00.730 --> 00:22:04.060
But because I create an empty
array, the initial

504
00:22:04.060 --> 00:22:05.490
object that I have--

505
00:22:05.490 --> 00:22:06.490
you'll see--

506
00:22:06.490 --> 00:22:07.890
doesn't actually have
any elements at all

507
00:22:07.890 --> 00:22:09.680
because it's empty.

508
00:22:09.680 --> 00:22:13.820
So the hidden class says,
hey, I'm an array.

509
00:22:13.820 --> 00:22:18.530
And I'm optimistically going
to assume it contains smi

510
00:22:18.530 --> 00:22:23.690
values and that I'm not going to
have any deletes, no holes.

511
00:22:23.690 --> 00:22:25.050
We can do that because
the arrays empty.

512
00:22:25.050 --> 00:22:27.210
So it's actually a
true statement.

513
00:22:27.210 --> 00:22:29.970
It only has smis because
it has nothing in it.

514
00:22:29.970 --> 00:22:33.230
What happens when we assigned
the first element of the

515
00:22:33.230 --> 00:22:36.190
array, because we didn't have
a backing store for the

516
00:22:36.190 --> 00:22:39.130
elements yet, we have
to allocate it.

517
00:22:39.130 --> 00:22:42.910
And by default, we allocate
a buffer that has

518
00:22:42.910 --> 00:22:45.420
room for four elements.

519
00:22:45.420 --> 00:22:47.870
Now that the backing store is
actually there, we can store

520
00:22:47.870 --> 00:22:48.920
the first element in here.

521
00:22:48.920 --> 00:22:51.520
And, again, this is stored as a
smi, as one of these compact

522
00:22:51.520 --> 00:22:54.860
31-bit signed integers.

523
00:22:54.860 --> 00:22:57.840
And now that we have space, we
can also assign the second

524
00:22:57.840 --> 00:23:00.360
element, also not a problem.

525
00:23:00.360 --> 00:23:05.440
However, the next assignment
assigns a double value.

526
00:23:05.440 --> 00:23:10.450
And what this does is forces
V8 to convert the format of

527
00:23:10.450 --> 00:23:15.530
the backing store, because we
can't store a double value

528
00:23:15.530 --> 00:23:16.750
directly into the array.

529
00:23:16.750 --> 00:23:18.610
But what we could do is we could
convert the existing

530
00:23:18.610 --> 00:23:20.500
integer values to doubles.

531
00:23:20.500 --> 00:23:24.060
And then, with the unboxed
version of this array, we

532
00:23:24.060 --> 00:23:26.080
could store the 0.5 value.

533
00:23:26.080 --> 00:23:27.510
And that's exactly
what V8 does.

534
00:23:27.510 --> 00:23:28.960
It reallocates a new buffer.

535
00:23:28.960 --> 00:23:32.970
This time each of the elements
slots is 64 bits.

536
00:23:32.970 --> 00:23:36.640
It converts the existing small
integers into double values.

537
00:23:36.640 --> 00:23:43.800
And then it assigns the 0.5
to the third element.

538
00:23:43.800 --> 00:23:45.670
You'll also notice that a hidden
class change happened

539
00:23:45.670 --> 00:23:48.810
here, because what we did
is added a double value.

540
00:23:48.810 --> 00:23:52.580
So it's no longer true that
the array only has smis.

541
00:23:52.580 --> 00:23:54.600
We now have doubles in there.

542
00:23:54.600 --> 00:23:56.615
That means that the hidden
class has to be changed.

543
00:23:56.615 --> 00:23:59.450
It causes a hidden
class change.

544
00:23:59.450 --> 00:24:02.760
Something similar happens when
we try to assign true.

545
00:24:02.760 --> 00:24:05.490
So true, there are certain
objects in JavaScript which

546
00:24:05.490 --> 00:24:07.130
are kind of oddballs.

547
00:24:07.130 --> 00:24:08.740
We actually call
them oddballs.

548
00:24:08.740 --> 00:24:12.960
True, undefined, null, they
are not really objects.

549
00:24:12.960 --> 00:24:14.240
But they kind of act
like objects.

550
00:24:14.240 --> 00:24:15.490
But they're certainly
not numbers.

551
00:24:15.490 --> 00:24:18.560
So when I assign true to the
third element or the fourth

552
00:24:18.560 --> 00:24:22.160
element here, it causes another
allocation because we

553
00:24:22.160 --> 00:24:26.890
can no longer represent this
new value in this unboxed

554
00:24:26.890 --> 00:24:27.420
double array.

555
00:24:27.420 --> 00:24:30.720
So we have to convert it back
into its tagged format, which

556
00:24:30.720 --> 00:24:34.650
means converting the elements
that can be represented as

557
00:24:34.650 --> 00:24:36.090
smis back into smis.

558
00:24:36.090 --> 00:24:39.370
It means reboxing the
double value.

559
00:24:39.370 --> 00:24:41.900
And now we have a backing store
that we can actually

560
00:24:41.900 --> 00:24:43.560
store the true value in.

561
00:24:43.560 --> 00:24:46.060

562
00:24:46.060 --> 00:24:47.440
That's a lot of work.

563
00:24:47.440 --> 00:24:48.430
This is a very short
piece of code.

564
00:24:48.430 --> 00:24:55.360
But we did four allocations,
two array, two hidden class

565
00:24:55.360 --> 00:24:58.150
changes for just a couple
lines of code.

566
00:24:58.150 --> 00:25:00.250
There is a better way.

567
00:25:00.250 --> 00:25:05.130
If you use an array literal,
this is a hint to V8 upfront

568
00:25:05.130 --> 00:25:08.630
what the values are going to
be inside of the array.

569
00:25:08.630 --> 00:25:11.170
And given this example here, we
have a single allocation.

570
00:25:11.170 --> 00:25:13.490
All of this can be done
in one allocation.

571
00:25:13.490 --> 00:25:17.980
The correct backing store format
can be selected at

572
00:25:17.980 --> 00:25:19.300
compile time.

573
00:25:19.300 --> 00:25:22.030
And we don't have all of these
conversions in the

574
00:25:22.030 --> 00:25:23.280
initialization of the array.

575
00:25:23.280 --> 00:25:25.670

576
00:25:25.670 --> 00:25:27.960
So touched on this already.

577
00:25:27.960 --> 00:25:30.690
Speed trap, make sure, wherever
possible, you

578
00:25:30.690 --> 00:25:34.890
initialize arrays with array
literals, especially for fixed

579
00:25:34.890 --> 00:25:38.180
size, small arrays.

580
00:25:38.180 --> 00:25:42.910
Also for small arrays, make
sure to preallocate them

581
00:25:42.910 --> 00:25:44.580
before you use them.

582
00:25:44.580 --> 00:25:46.150
Now, again, this is different
than large arrays.

583
00:25:46.150 --> 00:25:49.590
Large arrays, remember, more
than 65,000 elements, you want

584
00:25:49.590 --> 00:25:51.840
to make sure you grow as you go
so that you don't go into

585
00:25:51.840 --> 00:25:52.450
dictionary mode.

586
00:25:52.450 --> 00:25:56.390
For small arrays, even if
they're not completely filled,

587
00:25:56.390 --> 00:25:59.930
even if they're small, if
they're sparse, if they're

588
00:25:59.930 --> 00:26:04.650
small, V8 will use fast
elements for them.

589
00:26:04.650 --> 00:26:08.710
But only if you allocate the
correct size will you be able

590
00:26:08.710 --> 00:26:12.020
to avoid allocations when you
go from an empty array and

591
00:26:12.020 --> 00:26:15.410
store the first element
into it.

592
00:26:15.410 --> 00:26:18.380
Don't store non-numeric values
in numeric arrays.

593
00:26:18.380 --> 00:26:22.600
So if you have an array of
double values, V8 can generate

594
00:26:22.600 --> 00:26:25.370
very good code for manipulating
those values, for

595
00:26:25.370 --> 00:26:26.150
those double values.

596
00:26:26.150 --> 00:26:28.840
But if you put an object into
the array, we have to box

597
00:26:28.840 --> 00:26:29.500
everything again.

598
00:26:29.500 --> 00:26:34.660
And the code that we generate
is a lot less efficient.

599
00:26:34.660 --> 00:26:37.540
OK, we've talked about hidden
classes and how they are an

600
00:26:37.540 --> 00:26:39.810
important piece of
optimizing code.

601
00:26:39.810 --> 00:26:42.810
Let's actually talk about how
we generate code in V8.

602
00:26:42.810 --> 00:26:44.380
And this will maybe help you
understand a little bit better

603
00:26:44.380 --> 00:26:47.060
why it's important to make sure
that you understand the

604
00:26:47.060 --> 00:26:48.490
hidden classes.

605
00:26:48.490 --> 00:26:50.130
So a V8 has two compilers.

606
00:26:50.130 --> 00:26:52.300
The first one is called the full
compiler, because it can

607
00:26:52.300 --> 00:26:56.810
actually implement the full set
of JavaScript features.

608
00:26:56.810 --> 00:27:00.430
It generates good code
but not great code.

609
00:27:00.430 --> 00:27:01.870
There's an optimizing compiler,
which I'll talk

610
00:27:01.870 --> 00:27:05.500
about later, which produces much
better code for most of

611
00:27:05.500 --> 00:27:06.750
the language.

612
00:27:06.750 --> 00:27:08.380

613
00:27:08.380 --> 00:27:12.280
The goal of the full compiler
is to generate code quickly.

614
00:27:12.280 --> 00:27:14.830
I talked about before the fact
that any time you spend

615
00:27:14.830 --> 00:27:20.270
compiling code is added to
your execution time.

616
00:27:20.270 --> 00:27:23.610
So the full compiler strategy
is to get executing code as

617
00:27:23.610 --> 00:27:24.480
quickly as possible.

618
00:27:24.480 --> 00:27:27.430
It generates code that
is just good enough.

619
00:27:27.430 --> 00:27:30.230
But because of that,
it basically

620
00:27:30.230 --> 00:27:31.600
doesn't do any type analysis.

621
00:27:31.600 --> 00:27:34.430
It doesn't know anything
about types.

622
00:27:34.430 --> 00:27:39.200
And the way that it solves the
problem of implementing

623
00:27:39.200 --> 00:27:41.630
operations on different types
efficiently is a technique

624
00:27:41.630 --> 00:27:44.640
called inline caching
or inline caches.

625
00:27:44.640 --> 00:27:48.270
And what inline caches do is
they gather type information

626
00:27:48.270 --> 00:27:49.460
and run time.

627
00:27:49.460 --> 00:27:51.030
And they optimize the
code as you go.

628
00:27:51.030 --> 00:27:54.220
So you pay as you go.

629
00:27:54.220 --> 00:27:57.540
And here's the way inline
caches work.

630
00:27:57.540 --> 00:28:02.110
An inline cache, or an IC, is
a type-dependent small chunk

631
00:28:02.110 --> 00:28:05.850
of code that knows how to do
an operation given specific

632
00:28:05.850 --> 00:28:07.130
hidden class--

633
00:28:07.130 --> 00:28:09.840
inputs of a particular
hidden class.

634
00:28:09.840 --> 00:28:12.760
And what they do is they
validate the type assumptions.

635
00:28:12.760 --> 00:28:14.530
They get a couple
arguments in.

636
00:28:14.530 --> 00:28:15.750
They check to see if the hidden

637
00:28:15.750 --> 00:28:17.590
classes are as they expect.

638
00:28:17.590 --> 00:28:19.690
And if they are, then they know
that the code that is in

639
00:28:19.690 --> 00:28:22.950
the IC is the optimal code for
implementing that operation.

640
00:28:22.950 --> 00:28:25.160
If not, something
has to happen.

641
00:28:25.160 --> 00:28:27.620
A new IC has to be generated
that can handle the new type

642
00:28:27.620 --> 00:28:29.780
information.

643
00:28:29.780 --> 00:28:33.460
And at runtime, if different
types are seen than what are

644
00:28:33.460 --> 00:28:37.970
expected, then through
backpatching the code is

645
00:28:37.970 --> 00:28:41.290
changed to use new specialized
code for the new

646
00:28:41.290 --> 00:28:42.380
types that are seen.

647
00:28:42.380 --> 00:28:45.200
I'll give you an example
of how that works.

648
00:28:45.200 --> 00:28:49.330
Here's a fragment from the code
example at the beginning,

649
00:28:49.330 --> 00:28:50.420
a prime number generator.

650
00:28:50.420 --> 00:28:53.620
I'd like to take a particular
fragment of code there, which

651
00:28:53.620 --> 00:28:58.510
takes an element from the
prime's array and checks

652
00:28:58.510 --> 00:29:01.700
whether the candidate number is
divisible by that number.

653
00:29:01.700 --> 00:29:03.800
And let's see what the
full code generator

654
00:29:03.800 --> 00:29:04.850
does with this code.

655
00:29:04.850 --> 00:29:05.920
Don't sweat the details.

656
00:29:05.920 --> 00:29:07.760
I'm going to show some assembly
language here.

657
00:29:07.760 --> 00:29:10.370
And it's not actually
important what

658
00:29:10.370 --> 00:29:11.480
the details are here.

659
00:29:11.480 --> 00:29:14.460
But I want to show the pattern
of what actually goes on here.

660
00:29:14.460 --> 00:29:17.480
So each expression generates a
little chunk of code here.

661
00:29:17.480 --> 00:29:19.680
You'll see that there's some
preparation code and then

662
00:29:19.680 --> 00:29:25.870
there's a call out, a call to an
IC to actually do the work.

663
00:29:25.870 --> 00:29:29.340
Likewise, for the array element
access, there is some

664
00:29:29.340 --> 00:29:32.540
preparation work and then a call
out to the IC to do the

665
00:29:32.540 --> 00:29:35.630
work, and for the [INAUDIBLE]
the same thing.

666
00:29:35.630 --> 00:29:39.230
And the thing to notice here is
that, initially, the call

667
00:29:39.230 --> 00:29:43.380
is to this initialize version
of the IC, because we don't

668
00:29:43.380 --> 00:29:44.760
know what the types
are going to be.

669
00:29:44.760 --> 00:29:47.940
We'll only know that
at run time.

670
00:29:47.940 --> 00:29:49.410
And this is how it works
at run time.

671
00:29:49.410 --> 00:29:52.100
The code on the left here is a
small, almost impossible to

672
00:29:52.100 --> 00:29:54.470
read version of the code
I just showed you.

673
00:29:54.470 --> 00:29:58.240
And when we're executing this
code for the first time, and

674
00:29:58.240 --> 00:30:02.920
we get to this IC, the first
IC, it calls an internal

675
00:30:02.920 --> 00:30:04.580
routine that initializes
the IC.

676
00:30:04.580 --> 00:30:06.790
It looks at what the arguments
are to that operation the

677
00:30:06.790 --> 00:30:07.250
first time.

678
00:30:07.250 --> 00:30:09.050
It checks the hidden classes.

679
00:30:09.050 --> 00:30:10.670
And it says, oh, I know
how to do that.

680
00:30:10.670 --> 00:30:13.200
I can generate specialized
code for that.

681
00:30:13.200 --> 00:30:15.190
It does so.

682
00:30:15.190 --> 00:30:18.480
And it backpatches the address
so that the next time you come

683
00:30:18.480 --> 00:30:20.070
to the code, it does the
same thing again.

684
00:30:20.070 --> 00:30:23.330
Assuming that the next time you
run, you're going to have

685
00:30:23.330 --> 00:30:25.580
the same hidden classes, the
same types of objects, which

686
00:30:25.580 --> 00:30:28.320
is an optimistic but usually
valid assumption.

687
00:30:28.320 --> 00:30:32.740
It does the same thing for the
access of the array element

688
00:30:32.740 --> 00:30:35.990
and for the [? lot ?]
operation.

689
00:30:35.990 --> 00:30:39.880
And you'll see that each of
the ICs, all they are is

690
00:30:39.880 --> 00:30:44.640
specialized code that know how
to do the specific operation

691
00:30:44.640 --> 00:30:47.820
for a given set of object
types that are input.

692
00:30:47.820 --> 00:30:51.690

693
00:30:51.690 --> 00:30:53.470
This makes a big difference
in performance.

694
00:30:53.470 --> 00:30:56.200
And this is why you need to
understand how some of this

695
00:30:56.200 --> 00:30:58.550
stuff works with hidden classes,
because if you get it

696
00:30:58.550 --> 00:31:01.750
wrong, you don't actually get
the performance improvement

697
00:31:01.750 --> 00:31:04.830
that you will see or should see
when using ICs and then,

698
00:31:04.830 --> 00:31:06.480
later, the optimizing
compiler.

699
00:31:06.480 --> 00:31:08.790
So if you're running the sample
code that I showed at

700
00:31:08.790 --> 00:31:13.000
the beginning to generate primes
without ICs, you get an

701
00:31:13.000 --> 00:31:15.710
execution time that's
over 600 seconds.

702
00:31:15.710 --> 00:31:18.220
When you turn ICs on--

703
00:31:18.220 --> 00:31:20.030
don't have the optimizing
compiler on yet--

704
00:31:20.030 --> 00:31:22.070
it makes a big difference.

705
00:31:22.070 --> 00:31:26.295
So this is about a 20 times
speed improvement.

706
00:31:26.295 --> 00:31:29.480

707
00:31:29.480 --> 00:31:31.700
Now I'd like to introduce a
concept that we'll also come

708
00:31:31.700 --> 00:31:32.590
back to later.

709
00:31:32.590 --> 00:31:33.865
Monomorphic better
than polymorphic.

710
00:31:33.865 --> 00:31:35.360
It sounds pretty complicated.

711
00:31:35.360 --> 00:31:38.040
It isn't really.

712
00:31:38.040 --> 00:31:41.790
Monomorphic operations are
operations that always work on

713
00:31:41.790 --> 00:31:45.800
objects with the same
hidden classes.

714
00:31:45.800 --> 00:31:49.900
So the first time you execute an
IC, we look at the argument

715
00:31:49.900 --> 00:31:51.000
types for the operation.

716
00:31:51.000 --> 00:31:52.230
We look at the hidden classes.

717
00:31:52.230 --> 00:31:53.900
And we remember them.

718
00:31:53.900 --> 00:31:55.770
And if the next time, through
those hidden classes, are the

719
00:31:55.770 --> 00:31:58.020
same, it's monomorphic.

720
00:31:58.020 --> 00:32:01.090
And if the next time they're
the same, it's still

721
00:32:01.090 --> 00:32:01.530
monomorphic.

722
00:32:01.530 --> 00:32:03.200
And it stays that way.

723
00:32:03.200 --> 00:32:06.300
If at any time we see different
hidden classes for

724
00:32:06.300 --> 00:32:10.880
the arguments to an operation
then it becomes polymorphic.

725
00:32:10.880 --> 00:32:13.470
And it turns out that
monomorphic operations are

726
00:32:13.470 --> 00:32:14.135
easier to optimize.

727
00:32:14.135 --> 00:32:16.860
Or the code that we generate is
better than for polymorphic

728
00:32:16.860 --> 00:32:18.220
operations.

729
00:32:18.220 --> 00:32:21.020
So here's an example.

730
00:32:21.020 --> 00:32:25.260
Let's say we have a function
add that adds two things.

731
00:32:25.260 --> 00:32:29.480
And if I call that with two
integer arguments, it's

732
00:32:29.480 --> 00:32:31.150
monomorphic.

733
00:32:31.150 --> 00:32:34.680
However, if I call it again with
two string arguments, I

734
00:32:34.680 --> 00:32:36.870
use the same operation--
this plus operation--

735
00:32:36.870 --> 00:32:39.950
to work both on integers
and on strings.

736
00:32:39.950 --> 00:32:41.790
And at that moment, it
becomes polymorphic.

737
00:32:41.790 --> 00:32:45.180
And it becomes more difficult
for V8 to generate good,

738
00:32:45.180 --> 00:32:47.710
really efficient code for
that plus operation.

739
00:32:47.710 --> 00:32:51.820
So the speed trap to avoid here
is, wherever possible,

740
00:32:51.820 --> 00:32:59.420
don't try to mix operations or
objects of different types in

741
00:32:59.420 --> 00:33:01.470
operations at a particular
place in your code.

742
00:33:01.470 --> 00:33:04.540
Prefer monomorphic code
to polymorphic code

743
00:33:04.540 --> 00:33:05.790
wherever you can.

744
00:33:05.790 --> 00:33:09.240

745
00:33:09.240 --> 00:33:12.030
I'd like to talk about the
optimizing compiler.

746
00:33:12.030 --> 00:33:14.080
We talked about the full
compiler, generates pretty

747
00:33:14.080 --> 00:33:17.070
good code, gets executing
as fast as possible.

748
00:33:17.070 --> 00:33:20.420
The optimizing compiler comes
back later for the code that's

749
00:33:20.420 --> 00:33:22.885
really hot and recompiles
the hot functions.

750
00:33:22.885 --> 00:33:26.720

751
00:33:26.720 --> 00:33:27.570
Why does it do this?

752
00:33:27.570 --> 00:33:30.850
Well, we've gathered information
about the types of

753
00:33:30.850 --> 00:33:35.560
the objects that we're operating
on through the ICs.

754
00:33:35.560 --> 00:33:38.920
And the optimizing compiler can
take that information and

755
00:33:38.920 --> 00:33:42.820
make decisions about how to
optimize the code better.

756
00:33:42.820 --> 00:33:45.350
What happens is the optimizing
compiler takes that type

757
00:33:45.350 --> 00:33:46.900
information from the ICs.

758
00:33:46.900 --> 00:33:50.470
And it speculatively inlines a
version of the operation based

759
00:33:50.470 --> 00:33:54.940
on history, what it's seen
before in the ICs.

760
00:33:54.940 --> 00:33:59.600
And it also means that it can
inline function calls that are

761
00:33:59.600 --> 00:34:00.600
monomorphic.

762
00:34:00.600 --> 00:34:01.760
This includes constructors.

763
00:34:01.760 --> 00:34:06.050
This is actually a new feature
that we've added recently.

764
00:34:06.050 --> 00:34:09.620

765
00:34:09.620 --> 00:34:13.670
By enabling inlining, by
inlining this operation in the

766
00:34:13.670 --> 00:34:16.230
optimize code, other
optimizations become possible.

767
00:34:16.230 --> 00:34:18.320
And that's what the optimizing
compiler will actually do.

768
00:34:18.320 --> 00:34:21.590
We'll go over this inline code
and find more opportunities to

769
00:34:21.590 --> 00:34:23.810
make it faster.

770
00:34:23.810 --> 00:34:24.650
Let's see how that works.

771
00:34:24.650 --> 00:34:27.820
Again, a warning, here's
assembly code.

772
00:34:27.820 --> 00:34:32.739
It's a very similar process to
the full code generator.

773
00:34:32.739 --> 00:34:35.000
We generate a little piece
of code for each of the

774
00:34:35.000 --> 00:34:35.909
expressions.

775
00:34:35.909 --> 00:34:39.280
But this time, you'll notice,
as we generate each piece of

776
00:34:39.280 --> 00:34:41.590
code, there's no call
at the end.

777
00:34:41.590 --> 00:34:44.449
And in fact, when we're done,
it's straight line code.

778
00:34:44.449 --> 00:34:48.850

779
00:34:48.850 --> 00:34:52.566
So let's compare the performance
using the

780
00:34:52.566 --> 00:34:57.070
optimizing compiler with the two
runs that we did before.

781
00:34:57.070 --> 00:34:59.250
You'll see that with the
optimizing compiler, we're

782
00:34:59.250 --> 00:35:01.350
even fast-- we're about
50 times faster than

783
00:35:01.350 --> 00:35:02.600
the original code.

784
00:35:02.600 --> 00:35:04.850

785
00:35:04.850 --> 00:35:07.730
One thing that's really useful
is actually to find out which

786
00:35:07.730 --> 00:35:10.210
functions are being
optimized by the

787
00:35:10.210 --> 00:35:13.460
optimizing compiler in V8.

788
00:35:13.460 --> 00:35:16.090
So there's an option you can
pass to the DHL that

789
00:35:16.090 --> 00:35:16.860
will do just that.

790
00:35:16.860 --> 00:35:19.050
It'll output the information
about which

791
00:35:19.050 --> 00:35:20.300
functions get optimized.

792
00:35:20.300 --> 00:35:23.460

793
00:35:23.460 --> 00:35:25.920
However, there are certain
circumstances in which the

794
00:35:25.920 --> 00:35:29.070
optimizing compiler can't
optimize a function.

795
00:35:29.070 --> 00:35:30.940
This is called bailing out.

796
00:35:30.940 --> 00:35:33.100
Or that's what we call
it, bailing out.

797
00:35:33.100 --> 00:35:35.100
And the reason is there are
certain language features that

798
00:35:35.100 --> 00:35:39.790
are just not supported yet by
the optimizing compiler.

799
00:35:39.790 --> 00:35:43.380
The most obvious example
is try catch.

800
00:35:43.380 --> 00:35:45.810
So if you have a function that
contains a try catch block,

801
00:35:45.810 --> 00:35:49.830
the optimizing compiler, right
now, can't optimize that.

802
00:35:49.830 --> 00:35:51.590
We hope to change that
in the future.

803
00:35:51.590 --> 00:35:54.980
But until then, there's
a work around.

804
00:35:54.980 --> 00:35:57.490
If you have performance
sensitive code that you'd like

805
00:35:57.490 --> 00:36:01.130
to access from try
catch block, wrap

806
00:36:01.130 --> 00:36:02.670
it in its own function.

807
00:36:02.670 --> 00:36:03.370
Here's an example.

808
00:36:03.370 --> 00:36:05.850
We have a function that's
performance sensitive.

809
00:36:05.850 --> 00:36:09.060
We call that from the try piece
of a try catch block in

810
00:36:09.060 --> 00:36:11.670
another function.

811
00:36:11.670 --> 00:36:15.230
And by doing that, it allows
the optimizing compiler to

812
00:36:15.230 --> 00:36:18.020
optimize the performance
sensitive function, even

813
00:36:18.020 --> 00:36:20.722
though it can't optimize
the try catch block.

814
00:36:20.722 --> 00:36:23.320

815
00:36:23.320 --> 00:36:26.830
If you want to find out which
routines cannot be optimized

816
00:36:26.830 --> 00:36:29.790
by the optimizing compiler and
why, there's an option you can

817
00:36:29.790 --> 00:36:32.570
pass through the debugging shell
called trace bailout.

818
00:36:32.570 --> 00:36:37.950
And that'll actually tell you
the functions that could not

819
00:36:37.950 --> 00:36:39.200
be compiled and why.

820
00:36:39.200 --> 00:36:41.500

821
00:36:41.500 --> 00:36:45.110
The last thing I'd like to talk
about is deoptimization.

822
00:36:45.110 --> 00:36:48.100
So the optimizing compiler
is pretty good

823
00:36:48.100 --> 00:36:50.180
at generating code.

824
00:36:50.180 --> 00:36:51.690
But there's a catch.

825
00:36:51.690 --> 00:36:54.890
The optimizations that it
does are speculative.

826
00:36:54.890 --> 00:36:57.910
It makes the optimistic
assumption that what it has

827
00:36:57.910 --> 00:37:01.630
seen in the past is going to be
just like what it's going

828
00:37:01.630 --> 00:37:04.140
to see in the future.

829
00:37:04.140 --> 00:37:07.170
And that usually pays off,
because usually your code

830
00:37:07.170 --> 00:37:09.730
keeps running like
it has before.

831
00:37:09.730 --> 00:37:13.820
However, as with all optimistic
assumptions, that

832
00:37:13.820 --> 00:37:14.700
may not be the case.

833
00:37:14.700 --> 00:37:18.310
So when you're driving down the
Autobahn in Germany and

834
00:37:18.310 --> 00:37:21.680
you're doing 200 kilometers an
hour, sometimes you're working

835
00:37:21.680 --> 00:37:24.690
under the optimistic assumption
that you're not

836
00:37:24.690 --> 00:37:26.920
going to be caught going
over the speed limit.

837
00:37:26.920 --> 00:37:29.000
Remember, I told you there are
some stretches of the Autobahn

838
00:37:29.000 --> 00:37:30.340
with a speed limit.

839
00:37:30.340 --> 00:37:32.380
And you'll see out of the corner
of your eye, a red

840
00:37:32.380 --> 00:37:36.370
flash from two of these things
on the side of the road.

841
00:37:36.370 --> 00:37:38.590
And you've just been caught in
a speed trap, because your

842
00:37:38.590 --> 00:37:41.550
optimistic assumption that you
were not going to be caught

843
00:37:41.550 --> 00:37:43.650
speeding was wrong.

844
00:37:43.650 --> 00:37:44.080
And what do you do?

845
00:37:44.080 --> 00:37:45.050
You slam on the brakes.

846
00:37:45.050 --> 00:37:46.660
You slow down to the
speed limit.

847
00:37:46.660 --> 00:37:50.055
And you probably drive that
way for a while, slower.

848
00:37:50.055 --> 00:37:52.620

849
00:37:52.620 --> 00:37:54.270
There's a similar process
that happens in

850
00:37:54.270 --> 00:37:56.480
optimized code in V8.

851
00:37:56.480 --> 00:37:59.440
Invalid assumptions lead
to deoptimization.

852
00:37:59.440 --> 00:38:01.410
When one of the assumptions is
no longer true, when one of

853
00:38:01.410 --> 00:38:03.990
the hidden classes that you
get for an argument to an

854
00:38:03.990 --> 00:38:07.470
operation is not what you
expected, then the specialized

855
00:38:07.470 --> 00:38:09.540
code we generated is
no longer valid.

856
00:38:09.540 --> 00:38:10.720
And we have to deoptimize.

857
00:38:10.720 --> 00:38:11.750
What does that mean?

858
00:38:11.750 --> 00:38:14.170
That means we throw way the
optimize code, because we know

859
00:38:14.170 --> 00:38:16.630
the assumptions we made are just
simply no longer valid.

860
00:38:16.630 --> 00:38:19.660
We resume execution in the
right place in the full

861
00:38:19.660 --> 00:38:21.450
compiler code.

862
00:38:21.450 --> 00:38:23.260
So we can continue
our execution.

863
00:38:23.260 --> 00:38:25.740
But now it's at a slower speed,
because we're using the

864
00:38:25.740 --> 00:38:28.650
version of code that is
good, but not great.

865
00:38:28.650 --> 00:38:32.600
And a reoptimization of the
function might happen later,

866
00:38:32.600 --> 00:38:34.920
because we're going to continue
to gather type

867
00:38:34.920 --> 00:38:39.160
information in the ICs in
the full compiler code.

868
00:38:39.160 --> 00:38:42.150
But for the short term, you're
going to run more slowly.

869
00:38:42.150 --> 00:38:45.770
And what that means is that
deoptimization is something

870
00:38:45.770 --> 00:38:46.530
you want to avoid.

871
00:38:46.530 --> 00:38:49.210
And one way to do that is to
make sure that you don't

872
00:38:49.210 --> 00:38:52.910
introduce hidden class changes
at a late time

873
00:38:52.910 --> 00:38:53.850
running your code.

874
00:38:53.850 --> 00:38:57.740
If you have types, object types
that you run in optimize

875
00:38:57.740 --> 00:39:01.420
code, and V8 chooses to optimize
that code, and then

876
00:39:01.420 --> 00:39:04.720
you later introduce new types,
that optimize code will

877
00:39:04.720 --> 00:39:05.590
deoptimize.

878
00:39:05.590 --> 00:39:08.860
And if you do that too
often, it has a cost.

879
00:39:08.860 --> 00:39:13.090
You can tell the debugging shell
to output the routines,

880
00:39:13.090 --> 00:39:15.470
the functions that it optimizes
on by passing the

881
00:39:15.470 --> 00:39:18.340
trace deopt option to
the debug shell.

882
00:39:18.340 --> 00:39:21.560
And it'll output which one it
deoptimized on and why.

883
00:39:21.560 --> 00:39:24.110

884
00:39:24.110 --> 00:39:28.400
Now most of you are doing web
development, I assume.

885
00:39:28.400 --> 00:39:31.770
And therefore, you probably
want to be able to look at

886
00:39:31.770 --> 00:39:35.290
your code in Chrome, as well
as directly in the DHL.

887
00:39:35.290 --> 00:39:40.190
You can pass these options
that I've mentioned also

888
00:39:40.190 --> 00:39:43.090
directly to Chrome using
the js flags option.

889
00:39:43.090 --> 00:39:47.460
And the output will all show
up in standard out when

890
00:39:47.460 --> 00:39:49.080
running Chrome.

891
00:39:49.080 --> 00:39:51.315
OK, so that was the
be prepared part.

892
00:39:51.315 --> 00:39:56.150
You now understand a little
bit about how V8 works.

893
00:39:56.150 --> 00:39:58.630
Let's talk now about identifying
and understanding

894
00:39:58.630 --> 00:40:00.710
problems using that knowledge.

895
00:40:00.710 --> 00:40:02.020
What does that mean for V8?

896
00:40:02.020 --> 00:40:04.020
First of all, ensure the problem
that you're looking at

897
00:40:04.020 --> 00:40:05.680
is a JavaScript problem.

898
00:40:05.680 --> 00:40:08.160
And this is sometimes
a little bit tricky.

899
00:40:08.160 --> 00:40:11.910
You could use the dev tools in
Chrome to figure out where

900
00:40:11.910 --> 00:40:14.000
you're spending time in
your web application.

901
00:40:14.000 --> 00:40:15.170
It may look like JavaScript.

902
00:40:15.170 --> 00:40:17.740
But be careful it might be the
case that there's also DOM

903
00:40:17.740 --> 00:40:18.940
interaction.

904
00:40:18.940 --> 00:40:22.320
So a really good way to do that
is, if you can take that

905
00:40:22.320 --> 00:40:24.920
code that you think is the
performance bottleneck, pull

906
00:40:24.920 --> 00:40:27.720
it out, and run it in the DHL,
that means it's pure

907
00:40:27.720 --> 00:40:28.250
JavaScript.

908
00:40:28.250 --> 00:40:32.090
Because the V8 project is just
JavaScript, it doesn't have--

909
00:40:32.090 --> 00:40:32.990
it's integrated into Chrome.

910
00:40:32.990 --> 00:40:36.230
But it, in itself, is just
the JavaScript execution

911
00:40:36.230 --> 00:40:37.080
environment.

912
00:40:37.080 --> 00:40:40.330
So if you can take that code and
run it with the DHL, then

913
00:40:40.330 --> 00:40:41.140
you're pretty--

914
00:40:41.140 --> 00:40:43.130
then you can analyze the
problems of JavaScript only

915
00:40:43.130 --> 00:40:45.600
performance problem.

916
00:40:45.600 --> 00:40:48.710
Collect metrics, measure
where you're spending

917
00:40:48.710 --> 00:40:50.760
your time in the code.

918
00:40:50.760 --> 00:40:54.780
And then locate the bottlenecks
and fix them.

919
00:40:54.780 --> 00:40:57.770
So remember the example that we
had at the beginning, the

920
00:40:57.770 --> 00:41:00.140
prime number generator.

921
00:41:00.140 --> 00:41:03.820
If you run it in the shell and
pass an additional argument,

922
00:41:03.820 --> 00:41:10.190
the dash dash prof argument, it
will run the program while

923
00:41:10.190 --> 00:41:13.560
also sampling the execution
profile.

924
00:41:13.560 --> 00:41:16.140
And it'll write a log that you
can then analyze with another

925
00:41:16.140 --> 00:41:19.160
tool to see where you're
spending your time.

926
00:41:19.160 --> 00:41:21.520
Before we look at that output,
where we're spending the time,

927
00:41:21.520 --> 00:41:24.750
I'd like to go over briefly
again where we're spending the

928
00:41:24.750 --> 00:41:26.530
time-- or what we're doing
in the program.

929
00:41:26.530 --> 00:41:28.210
There's a couple important
functions here

930
00:41:28.210 --> 00:41:29.020
in the prime generator.

931
00:41:29.020 --> 00:41:31.250
First, we add a prime.

932
00:41:31.250 --> 00:41:33.950
There's a function to add a
prime to the existing list.

933
00:41:33.950 --> 00:41:35.360
There's a function that
actually tests whether

934
00:41:35.360 --> 00:41:40.090
candidate number is divisible or
is divisible by one of the

935
00:41:40.090 --> 00:41:41.550
existing primes.

936
00:41:41.550 --> 00:41:44.180
And then there's the main
routine, which does the high

937
00:41:44.180 --> 00:41:45.480
level algorithm.

938
00:41:45.480 --> 00:41:48.240
It starts at one, goes up,
checks that number, whether

939
00:41:48.240 --> 00:41:50.570
it's divisible by an
existing prime.

940
00:41:50.570 --> 00:41:53.060
If not, it adds it to the prime
list, otherwise it goes

941
00:41:53.060 --> 00:41:54.030
to the next number.

942
00:41:54.030 --> 00:41:56.010
So what's our expectation?

943
00:41:56.010 --> 00:41:57.460
The prediction is that we're
going to spend most of the

944
00:41:57.460 --> 00:41:58.330
time in main.

945
00:41:58.330 --> 00:42:00.720
And the reason for that is all
properties and functions are

946
00:42:00.720 --> 00:42:02.180
monomorphic.

947
00:42:02.180 --> 00:42:03.650
I wrote the code
to be that way.

948
00:42:03.650 --> 00:42:05.540
All numeric operations
are smis.

949
00:42:05.540 --> 00:42:08.670
We do a pretty good job
at optimizing those.

950
00:42:08.670 --> 00:42:11.790
All the functions could
be inlined.

951
00:42:11.790 --> 00:42:13.390
And there are no deoptimizations
or bailouts.

952
00:42:13.390 --> 00:42:16.390
So my expectation is V8 is going
to do a really good job

953
00:42:16.390 --> 00:42:17.520
of optimizing this code.

954
00:42:17.520 --> 00:42:19.910
OK, so let's take a look at the
output and see where we

955
00:42:19.910 --> 00:42:22.430
were spending our time.

956
00:42:22.430 --> 00:42:27.040
So this is the output of
the tick processor.

957
00:42:27.040 --> 00:42:28.600
It takes this output log
that's written with

958
00:42:28.600 --> 00:42:30.510
performance data.

959
00:42:30.510 --> 00:42:31.830
And it prints it in
a pretty format.

960
00:42:31.830 --> 00:42:33.500
You see there's two sections
of the output here.

961
00:42:33.500 --> 00:42:35.180
I've actually abridged this.

962
00:42:35.180 --> 00:42:36.290
It's much longer.

963
00:42:36.290 --> 00:42:38.500
But these are the important
parts for our profile here.

964
00:42:38.500 --> 00:42:39.510
There's a JavaScript section.

965
00:42:39.510 --> 00:42:42.160
This is the time we're spending
in generated code.

966
00:42:42.160 --> 00:42:46.820
This is JavaScript code
executing in either the full

967
00:42:46.820 --> 00:42:48.740
compiler code or
optimize code.

968
00:42:48.740 --> 00:42:52.570
And then there's the C++
section, which is--

969
00:42:52.570 --> 00:42:54.660
it's often the case that you'll
have C++ symbols in the

970
00:42:54.660 --> 00:42:57.560
profile, because there's some
operations that we can't do in

971
00:42:57.560 --> 00:42:58.070
generated code.

972
00:42:58.070 --> 00:42:59.970
So we have to call out.

973
00:42:59.970 --> 00:43:04.310
And as expected, we spend
a lot of time in main.

974
00:43:04.310 --> 00:43:05.650
But it's actually about 25%.

975
00:43:05.650 --> 00:43:06.770
You'll see there's three
columns here.

976
00:43:06.770 --> 00:43:10.740
You see how many ticks you're
spending in that routine, in

977
00:43:10.740 --> 00:43:11.815
this function.

978
00:43:11.815 --> 00:43:14.560
And you'll see what the
percentage is of the overall

979
00:43:14.560 --> 00:43:16.010
execution time.

980
00:43:16.010 --> 00:43:17.400
But in this case
it's only 25%.

981
00:43:17.400 --> 00:43:20.570
That's weird because I
expected a lot more.

982
00:43:20.570 --> 00:43:22.740
V8 should do a really good
job on this code.

983
00:43:22.740 --> 00:43:24.720
If you look at the other items
that show up in this profile,

984
00:43:24.720 --> 00:43:25.410
this is weird.

985
00:43:25.410 --> 00:43:28.260
We're spending time
doing a binary op

986
00:43:28.260 --> 00:43:29.990
stub with an oddball.

987
00:43:29.990 --> 00:43:31.440
An oddball, remember, I told
you those are things like

988
00:43:31.440 --> 00:43:33.530
true, undefined, and null.

989
00:43:33.530 --> 00:43:34.220
We don't have that
in our code.

990
00:43:34.220 --> 00:43:35.540
That's kind of strange.

991
00:43:35.540 --> 00:43:36.590
And we're spending
a lot of time in

992
00:43:36.590 --> 00:43:38.400
library code doing modulo.

993
00:43:38.400 --> 00:43:40.340
And that's kind of strange.

994
00:43:40.340 --> 00:43:42.020
We should be able to inline
that as well.

995
00:43:42.020 --> 00:43:42.850
I didn't expect that.

996
00:43:42.850 --> 00:43:44.100
And then here's another one
that's kind of weird.

997
00:43:44.100 --> 00:43:46.490
We're doing a conversion
from a number--

998
00:43:46.490 --> 00:43:47.840
extracting--

999
00:43:47.840 --> 00:43:50.830
we're taking a number
and boxing it.

1000
00:43:50.830 --> 00:43:55.950
And we really should be
generating very good code for

1001
00:43:55.950 --> 00:43:57.180
this program.

1002
00:43:57.180 --> 00:43:58.740
We're spending way too much time
doing something that's

1003
00:43:58.740 --> 00:44:01.170
not executing the JavaScript.

1004
00:44:01.170 --> 00:44:02.310
We're calling out
to libraries.

1005
00:44:02.310 --> 00:44:05.200
Something is very wrong
with this code.

1006
00:44:05.200 --> 00:44:08.140
So can you spot the bug?

1007
00:44:08.140 --> 00:44:13.140
The hint is, is that our array
is only of length prime count.

1008
00:44:13.140 --> 00:44:17.070
And we've actually exceeded the
end of the array in our

1009
00:44:17.070 --> 00:44:18.030
calculations.

1010
00:44:18.030 --> 00:44:20.770
And in both the C++ and
JavaScript version, it doesn't

1011
00:44:20.770 --> 00:44:22.980
make a difference
in the results.

1012
00:44:22.980 --> 00:44:26.350
And this is the thing that
you've got to watch out for,

1013
00:44:26.350 --> 00:44:29.600
is that even though you don't
see that there's a problem in

1014
00:44:29.600 --> 00:44:31.810
the results, the program's
a lot slower

1015
00:44:31.810 --> 00:44:32.460
than it needs to be.

1016
00:44:32.460 --> 00:44:33.310
So let's fix that.

1017
00:44:33.310 --> 00:44:37.790
Let's actually not do an
out-of-bounds array access.

1018
00:44:37.790 --> 00:44:42.470
And we'll re-run the profile
with the fix.

1019
00:44:42.470 --> 00:44:45.000
And you'll see this time, this
is what we were expecting.

1020
00:44:45.000 --> 00:44:50.450
That small change now makes us
generate much better code

1021
00:44:50.450 --> 00:44:52.960
because we're not accessing
outside of the array, getting

1022
00:44:52.960 --> 00:44:55.490
an undefined object-- this
oddball-- that we're trying to

1023
00:44:55.490 --> 00:44:57.530
do math on.

1024
00:44:57.530 --> 00:45:00.750
And now we're spending over
99% of our time in main.

1025
00:45:00.750 --> 00:45:01.760
This is what we expected.

1026
00:45:01.760 --> 00:45:04.840
So let's see actually how big of
a difference this makes on

1027
00:45:04.840 --> 00:45:05.660
the profile.

1028
00:45:05.660 --> 00:45:09.130
And when we run the code against
the C++ code again,

1029
00:45:09.130 --> 00:45:10.580
look at that.

1030
00:45:10.580 --> 00:45:14.130
C++ code, three seconds,
JavaScript, 1.8 seconds--

1031
00:45:14.130 --> 00:45:18.452
we're 60% faster.

1032
00:45:18.452 --> 00:45:22.520
Well, I forgot to optimize
the C++ code.

1033
00:45:22.520 --> 00:45:26.870
So when you do that, C++
is still faster.

1034
00:45:26.870 --> 00:45:28.960
But it's 17% faster.

1035
00:45:28.960 --> 00:45:31.010
It's ball park.

1036
00:45:31.010 --> 00:45:32.460
I have to take all of this
with a grain of salt.

1037
00:45:32.460 --> 00:45:34.370
I chose an example where
I knew V8 would do a

1038
00:45:34.370 --> 00:45:36.600
pretty darn good job.

1039
00:45:36.600 --> 00:45:41.680
More and more, we're optimizing
more cases that

1040
00:45:41.680 --> 00:45:45.240
makes V8 faster in
more situations.

1041
00:45:45.240 --> 00:45:47.940
So I expect in the future, we'll
get closer and closer.

1042
00:45:47.940 --> 00:45:50.500
But my point here is that
you need to make sure

1043
00:45:50.500 --> 00:45:51.650
to take a look at--

1044
00:45:51.650 --> 00:45:54.140
spend the time optimizing your
code to know where you're

1045
00:45:54.140 --> 00:45:56.480
spending your time, because
you can actually make your

1046
00:45:56.480 --> 00:45:58.850
code very fast.

1047
00:45:58.850 --> 00:46:02.680
So fix what matters.

1048
00:46:02.680 --> 00:46:05.960
We did a lot of time analyzing
our existing profile, tweaking

1049
00:46:05.960 --> 00:46:08.280
it, knowing how V8 works.

1050
00:46:08.280 --> 00:46:10.940
The last thing I'd like to point
out is, make sure you

1051
00:46:10.940 --> 00:46:13.640
don't forget to optimize
your algorithm.

1052
00:46:13.640 --> 00:46:16.710
So I have a new version of the
program here, where instead of

1053
00:46:16.710 --> 00:46:19.790
iterating over all the prime
numbers, I only iterate to the

1054
00:46:19.790 --> 00:46:21.860
square root of the candidate,
which is sufficient to

1055
00:46:21.860 --> 00:46:26.480
actually test for whether it can
be divided by one of the

1056
00:46:26.480 --> 00:46:27.320
prime numbers.

1057
00:46:27.320 --> 00:46:29.995
And if I run that result--

1058
00:46:29.995 --> 00:46:32.150
if I run that in the--

1059
00:46:32.150 --> 00:46:34.537
I time that, then you'll
see that now I'm

1060
00:46:34.537 --> 00:46:38.050
under 5/100 of a second.

1061
00:46:38.050 --> 00:46:39.660
And if we compare that with the
original version, which

1062
00:46:39.660 --> 00:46:45.940
was 15 seconds, that's
350 times speed up.

1063
00:46:45.940 --> 00:46:50.740
So, in summary, keep your
eyes on the road.

1064
00:46:50.740 --> 00:46:51.330
Be prepared.

1065
00:46:51.330 --> 00:46:54.140
Learn a little bit about
how V8 works.

1066
00:46:54.140 --> 00:46:58.170
Identify and understand the
crux of your problem.

1067
00:46:58.170 --> 00:47:00.000
And fix the thing
that matters.

1068
00:47:00.000 --> 00:47:01.640
You don't have a whole lot
of time to do performance

1069
00:47:01.640 --> 00:47:02.520
optimization.

1070
00:47:02.520 --> 00:47:05.880
Make sure that every
minute counts.

1071
00:47:05.880 --> 00:47:07.260
And my friend Michael is fine.

1072
00:47:07.260 --> 00:47:10.660
He had taught me how to tie a
special knot, which freed my

1073
00:47:10.660 --> 00:47:12.530
hands while he was hanging.

1074
00:47:12.530 --> 00:47:16.320
I was able to call on my cell
phone the mountain rescue.

1075
00:47:16.320 --> 00:47:17.950
Michael regained consciousness,
and I could

1076
00:47:17.950 --> 00:47:19.040
lower him down.

1077
00:47:19.040 --> 00:47:21.600
The helicopter came and took
us off the mountain.

1078
00:47:21.600 --> 00:47:26.600
So even though he had a couple
broken ribs, he's fine.

1079
00:47:26.600 --> 00:47:27.400
Thank you.

1080
00:47:27.400 --> 00:47:34.553
[APPLAUSE]

